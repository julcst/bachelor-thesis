
\chapter{Neural Radiance Caching}
\label{chap:nrc}

A weak point of the reference Monte Carlo pathtracer motivated in \ref{chap:pathtracing} is, that we have to start from zero, every time the scene or camera changes.
It would make sense to keep samples around that can be reused when temporally and spatially similar paths occur in the evaluation of the global illumination integral.
\textcite{muller2021} introduced Neural Radiance Caching (NRC) to address this problem.
The idea is to train a neural network on collected radiance samples and use it to accumulate and interpolate these samples online.

Effectively, the idea is to replace the recursive path tracing integral with a neural estimate of the radiance when the variance along the path becomes too high.
The Neural Radiance Cache can be interpreted as a classical cache that uses gradient descent for a temporally smooth cache update and the generalization capabilities of neural networks to interpolate between cached samples.
However, this approach could also be viewed as a form of denoising of the radiance field, which is why it is a good mean to reduce variance in the final image.

\section{Network Architecture}
Because the network has to be trained and evaluated in real-time, \textcite{muller2021} propose to use a rather small hardware-accelerated network architecture.
They use a fully connected network with 5 hidden layers, with 64 neurons and ReLU activation each.
The output layer has 3 neurons, one for each color channel.
Additionally, they omit biases as they did not observe a measurable benefit, and it simplifies the implementation.
Because of the shallow architecture, skip connections are not needed to preserve the gradient flow.

To maximize the inference and training performance, \textcite{muller2021} introduce a fully fused implementation of the network, which fully utilizes shared memory and per-thread registers.
For this, the whole network is implemented as a single CUDA kernel, with each block handling a batch of 128 64-dimensional input vectors and keeping the $64\times128$ activations in shared memory.
Each block then consists of 4 warps, computing 16 neuron activations of the network each by applying a $16\times64$ matrix multiplication and the element-wise activation function.
For this, the hardware accelerated $16\times16$ FP16 matrix multiplication instruction is used when available.
With this hardware-optimized implementation, \textcite{muller2021} achieve a speedup of $5\times$ to $10\times$ compared to the widely used TensorFlow framework \bcite{tensorflow} on large batch sizes corresponding to HD resolution.

\section{Input Encodings}
\begin{table}
    \centering
    \begin{tabular}{l l l}
        %\toprule
        \textbf{Parameter} & \textbf{Encoding} & \textbf{Dimensions} \\
        \midrule
        Position $\vec{x} \in \mathbb{R}^3$ & $\mathrm{mhe}(\vec{x}) \in \mathbb{R}^{16 \times 2}$ & 0--31 \\
        Direction $\wo \in \mathbb{R}^3$ & $\mathrm{ob}(\wo) \in \mathbb{R}^{8}$ & 32--39 \\
        Normal $\vec{n}(\vec{x}) \in \mathbb{R}^3$ & $\mathrm{ob}(\vec{n}(\vec{x})) \in \mathbb{R}^{8}$ & 40--47 \\
        Roughness $r(\vec{x}) \in [0,1]$ & $\mathrm{ob}(r(\vec{x})) \in \mathbb{R}^{8}$ & 48--55 \\
        Diffuse reflectance $\vec{F}_d(\vec{x}, \wo) \in [0,1]^3$ & $\vec{F}_d(\vec{x}, \wo) \in \mathbb{R}^{3}$ & 56--58 \\
        Specular reflectance $\vec{F}_s(\vec{x}, \wo) \in [0,1]^3$ & $\vec{F}_s(\vec{x}, \wo) \in \mathbb{R}^{3}$ & 59--61 \\
        Padding $\vec{1} \in \mathbb{R}^2$ & $\vec{1} \in \mathbb{R}^2$ & 62--63 \\
        %\bottomrule
    \end{tabular}
    \caption{The components of the 64-dimensional input vector to the neural network.}
    \label{tab:input-encoding}
\end{table}
As shown by \textcite{ren2013}, parametrizing the network with the outgoing direction $\wo$ and the position $\vec{x}$ alone is not sufficient for an accurate representation of the radiance field.
Instead, it proves beneficial to include the surface normal $\vec{n}$, surface roughness $r$ and the expected diffuse and specular reflectance terms $\vec{F}_d$ and $\vec{F}_s$ as well.

Furthermore, the correlation between the outgoing radiance and the input features $\vec{x}$, $\wo$, $\vec{n}$ and $r$ is highly non-linear, so additional effort is required to linearize the input space, as neural networks approximate (roughly) linear functions more efficiently.
The diffuse and specular reflectance on the other hand can be used directly, as the outgoing radiance will essentially be a linear combination of these two terms.

\subsection{Positional Encoding}

\subsubsection{Triangle Wave Encoding}
A natural idea to linearize the input space is to find a set of orthonormal basis functions.
This enables the neural network to approximate arbitrarily complex functions on the input space as a linear combination of these basis functions.
A very famous such basis set is the Fourier series, which forms a basis for the space of square-integrable functions on the interval $[0, 1]$.
Square-integrability is not really a constraint, as it essentially assumes finite energy, which is a reasonable assumption to make for the radiance field.
Neither is the limitation to $[0, 1]$, as we can always normalize the input to the bounding box of the scene.
Such types of encodings were first used in language processing by \textcite{vaswani2017} and later adapted to computer graphics by \textcite{tancik2020} and to neural radiance fields by \textcite{mildenhall2022}.

However, for practical applications, compromises are necessary.
Firstly, \textcite{tancik2020} make the assumption that the output field is separable in the input dimensions, which is not generally true and leads to prominent stripe artifacts in the output if the network is to shallow.
Yet, this allows them to apply the Fourier transform individually per input dimension and brings the number of coefficients down from exponential to linear in the number of dimensions.
The hope is, that the neural network can compensate for the missing information.
This is generally possible, as every non-separable function can be approximated by a linear combination of separable functions, for example by writing the function as a tensor and applying tensor decomposition.
Additionally, \textcite{muller2021} omit the cosine terms and approximate the sine terms with triangle waves, which they found to reduce the number of coefficients and the computational cost without visibly affecting the output quality.

\subsubsection{Instant Neural Graphic Primitives}
In a follow-up work, \textcite{muller2022} propose a new positional encoding scheme, which they call Multiresolution Hash Encoding (MHE).
The idea is, to distribute feature vectors in a hierarchical grid in space.
For a given input position $\vec{x}$ and for each grid level a feature vector is then obtained by linearly interpolating the feature vectors at the corners of the current grid cell.
The individual feature vectors are concatenated and used as input to the neural network.
During training, the gradient is propagated back to the feature vectors.
To reduce the size of the backing feature grid and to better represent sparse fields, \textcite{muller2022} use a hash table per grid level.
For the hyperparametrization of the grid, \textcite{muller2022} empirically found 16 levels with 2 features per grid level to be Pareto optimal for their applications, which I adopt here as well.


\subsection{Directional Encoding}

\subsubsection{Spherical Harmonics}
A popular choice for the encoding of direction vectors is the use of spherical harmonics.
This is a natural choice, as the spherical harmonics form an orthonormal basis for the space of square-integrable functions defined on the unit sphere, so every function on directions can be represented as a linear combination of spherical harmonics, whose coefficients can be learned by the neural network.
However, the number of basis functions is quadratic in the degree $m$, which limits us to a maximum degree of $m=3$ for the 64-dimensional input vector, and they are relatively expensive to compute.
The limited degree also hinders the representation of high-frequency details in the radiance field.
Thus, I also explore alternative encodings for $\wo$ and $\vec{n}$.

\subsubsection{One Blob and One Blob Diffuse Encoding}
\begin{figure}
    \centering
    \begin{subfigure}{0.5\textwidth}
        \centering
        \input{figures/py/oneblob.pgf}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
        \centering
        \input{figures/py/oneblob_wrap.pgf}
    \end{subfigure}
    \caption{Visualization of the activations of the One Blob Encoding for a 1D input space with 4 bins using the quartic approximation of the Gaussian distribution. Left without wrapping at the edges right with.}
    \label{fig:oneblob}
\end{figure}
For bounded domains, \textcite{muller2019} propose a simple encoding scheme, which is a continuous generalization of the popular one-hot encoding, they call One Blob Encoding.
The idea is, to divide the input space into a fixed number of bins along each dimension.
Each input vector is then assumed to be distributed over the bins by a Gaussian distribution and the activation of the bin is the probability of the input vector to fall into that bin.
This probability is simply the integral of the PDF over the bin, which can be computed using the cumulative distribution function (CDF):
\begin{equation}
    \mathrm{ob}(x)_i = \probability{b_i \leq x < b_{i+1}} = \probability{x < b_{i+1}} - \probability{x < b_i},
\end{equation}
where $b_i$ and $b_{i+1}$ are the boundaries of the $i$-th bin.
To improve performance, \textcite{muller2021} approximate the Gaussian distribution with a fourth order polynomial.

This encoding is used by \textcite{muller2021} on the roughness but also on the direction vectors $\wo$ and $\vec{n}$, by first converting these to spherical coordinates and then using the azimuthal angle $\phi$ and the polar angle $\theta$ as input.
However, the azimuthal angle is periodic, so the encoding has also to be periodic to avoid discontinuities at the boundaries.
To achieve this, \textcite{muller2021} use a wrapped CDF (see \autoref{fig:oneblob}), which comes with the added benefit of being able to compute just one boundary per thread and obtaining the other through warp shuffling.
However, this encoding is not perfect as it establishes visible discontinuities at the poles.

To avoid these discontinuities, I implemented a variant of the One Blob Encoding which can be selectively disabled for diffuse surfaces by passing IEEE 754 NaNs as input.
For such surfaces, the direction vector $\wo$ is irrelevant, as we use the constant Lambertian reflectance model.
Thus, to omit $\wo$ without breaking the encoding, I assume that the distribution of the input values converges to a uniform distribution over all bins, which is equivalent to a constant activation value of $1 / n$ for each bin.

\subsubsection{Positional Encoding on an Octahedron}

\subsubsection{Positional Encoding of the Unit Sphere}

\subsection{Reflectance Factorization}
To help the neural network learn the radiance field, \textcite{muller2021} propose to multiply the network output with the sum of the mean diffuse and specular reflectance terms:
\begin{equation}
    \widehat{L}'(\vec{x}, \wo) = \left( \vec{F}_d(\vec{x}, \wo) + \vec{F}_s(\vec{x}, \wo) \right) \cdot \mathrm{NRC}(\vec{x}, \wo),
\end{equation}
This way the variance in the training data is reduced, as the remaining part is approximately reduced to just the incoming radiance which is commonly low frequent.
Note however, that these terms are nonetheless given as input, so this information is already available to the network and this is merely a normalization of the training data.
% TODO: Check
% TODO: Mean BRDF
% TODO: Explain missing transmissive term

\subsection{Emission Factorization}
Besides the reflectance factorization, I chose to exclude the emission term from the Neural Radiance Cache and only learn the integral part of the outgoing radiance:
\begin{equation}
    \widehat{L}(\vec{x}, \wo) = L_e(\vec{x}, \wo) + \left( \vec{F}_d(\vec{x}, \wo) + \vec{F}_s(\vec{x}, \wo) \right) \cdot \mathrm{NRC}(\vec{x}, \wo),
\end{equation}
This is because the emission term is usually magnitudes higher than the rest of the radiance field and only sparsely present, which leads to high variance in the training data and can lead to leaking of emission into other regions of the cache.
In addition, it does not affect performance, as the emission is directly given by the scene geometry, so we can simply add it during inference.

\section{Training}

\subsection{Collecting Training Data}
\begin{algorithm}
    \caption{Back transportation of radiance along the training paths}
    \label{alg:backtransport}
    \begin{algorithmic}
        \State $\vec{L}_T \gets \vec{L_e}$
        \For{$i \in (n - 1), \dots, 1$}
            \State $\vec{L}_T \gets w_i \cdot \vec{L}_T$ \Comment{Transport radiance to previous vertex}
            \State $\vec{L}_i \gets \vec{L}_i + \vec{L}_T$ \Comment{Accumulate radiance at vertex}
        \EndFor
    \end{algorithmic}
\end{algorithm}
\textcite{muller2021} combine the training data collection with the inference step by extending a fraction of the inference paths with additional training bounces to avoid redundant path tracing.
However, as I want to mix different training techniques and to keep flexibility with the implementation, I chose to separate the training data collection from the inference step, accepting potential performance penalties.
Nevertheless, the training sample acquisition is the same:
I trace paths from the camera to the scene, using Russian Roulette termination (\autoref{eq:rr}) and Next Event Estimation (\autoref{sec:mis}).
At each vertex of the path, I store the current contribution weight and the input vector.
When I sample an emitter, I can then use these weights to transport the radiance back to the previous vertices (see \autoref{alg:backtransport}).

To store the training data, I use a fixed-size ring buffer with an atomic counter to ensure thread safety.
This is not ideal, as it may lead to serialization of the GPU threads and thus potentially introduces a performance bottleneck, but it allows me to write dynamic amounts of data per thread.
Further research could be done to find a more efficient way to store the training data, for example using warp aggregation and compaction, but this is not straightforward as OptiX does not expose shared memory to allow for Shader Execution Reordering.

\subsection{Self-Learning}
Furthermore, \textcite{muller2021} propose a self-learning approach, which trades additional bias for reduced variance in the training data.
The idea is, to terminate the training paths into the radiance cache from the previous frame to simulate infinite length paths.
Because this can amplify the existing bias in the network prediction, they terminate $1/16$ of the training paths in an unbiased manner without self-learning but by Russian Roulette.
% TODO: Russian Roulette

\subsection{Loss Function}
Because we use Monte Carlo Sampling to generate the training data, we want the network to learn the mean of the samples in a local region and we assume the samples to be normally distributed by the central limit theorem, so the loss function should be the squared error loss (L2).

However, the network prediction may cover a high dynamic range, especially when the scene contains caustics or highly glossy materials.
The traditional L2 loss would thus disproportionately penalize losses in these regions, leading to possible overfitting on bright regions and bad representation of dark regions.
To mitigate this, \textcite{lehtinen2018} propose to normalize the L2 loss by the squared prediction of the network.
I use the modification of \textcite{muller2021}, who use the squared \emph{luminance} of the prediction instead to prevent overfitting onto individual color channels.

\section{Inference}
Using the described training process, the Neural Radiance Cache learns an approximation of the outgoing radiance field, denoted as $\widehat{L}(\vec{x}, \wo)$.
For inference, short paths are traced from the camera to the scene using BSDF sampling, the resulting contribution $I$ is then the throughput along the path multiplied with the radiance estimate at the terminal vertex.
The length of the inference paths is a trade-off between bias and variance, as longer paths can cover up cache inaccuracies but introduce Monte Carlo noise.
This is analogous to Final Gathering in Photon Mapping \bcite{jensen1996}.
In the following, I will thus discuss different strategies for path termination.

\subsection{Path Termination Strategies}
\textbf{1st Vertex} Terminating directly at the first path vertex is a simple strategy that is well suited to visualize the weaknesses of the radiance cache, but is a rather poor choice for glossy vertices that expose high frequency details in the radiance field.

\textbf{Variance Heuristic} \textcite{muller2021} propose to terminate paths instead based on the estimated variance of the sampled path.
Low variance paths should be path traced, because they exhibit high frequent detail and importance sampling these paths is likely to yield a good estimate.
High variance paths on the other hand result in high Monte Carlo noise

\subsection{Temporal Stability}
Because the neural network is trained continuously with a relatively high learning rate on highly dynamic data, the output of the network can become temporally unstable.
As a solution to this apparent flickering effect, \textcite{muller2021} propose to use an exponential moving average over the network weights for inference.
Note, however, that this is used exclusively for inference, leaving the training process unchanged.