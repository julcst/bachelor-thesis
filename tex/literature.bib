@online{abrash1996,
  title = {Quake's {{Lighting Model}}:~ {{Surface Caching}}},
  author = {Abrash, Michael},
  date = {1996},
  url = {https://www.bluesnews.com/abrash/chap68.shtml},
  urldate = {2025-04-22},
  file = {/Users/julianstamm/Zotero/storage/UGNLCZC6/chap68.html}
}

@online{acceleratedphotonmappinghardwarebasedraytracingjcgt,
  title = {Accelerated {{Photon Mapping}} for {{Hardware-based Ray Tracing}} ({{JCGT}})},
  url = {https://jcgt.org/published/0012/01/01/},
  urldate = {2025-05-13},
  file = {/Users/julianstamm/Zotero/storage/JDRJSYI2/Accelerated Photon Mapping for Hardware-based Ray Tracing (JCGT).pdf;/Users/julianstamm/Zotero/storage/BMFWUVG5/01.html}
}

@unpublished{ahmed2019,
  title = {My {{Favorite Samples}}},
  author = {Ahmed, Abdalla and Keller, Alexander and Georgiev, Iliyan and Pharr, Matt and Christensen, Per},
  date = {2019},
  url = {https://www.youtube.com/},
  urldate = {2024-09-24},
  eventtitle = {{{SIGGRAPH Courses}}},
  langid = {english},
  venue = {Los Angeles, California},
  file = {/Users/julianstamm/Zotero/storage/KQ7ASC6B/watch.html}
}

@unpublished{apers2024,
  title = {Shipping {{Dynamic Global Illumination}} in {{Frostbite}}},
  author = {Apers, Diede},
  date = {2024},
  url = {https://advances.realtimerendering.com/s2024/content/EA-GIBS2/Apers_Advances-s2024_Shipping-Dynamic-GI.pdf},
  urldate = {2025-05-04},
  file = {/Users/julianstamm/Zotero/storage/IACBIS7H/Apers_Advances-s2024_Shipping-Dynamic-GI.pdf}
}

@inproceedings{arvo1986,
  title = {Backward Ray Tracing},
  booktitle = {Developments in Ray Tracing, Computer Graphics, Proc. of {{ACM SIGGRAPH}} 86 Course Notes},
  author = {Arvo, James and others},
  date = {1986},
  pages = {259--263},
  file = {/Users/julianstamm/Zotero/storage/BYYX7CC2/Backward.pdf}
}

@inproceedings{barron2021,
  title = {Mip-{{NeRF}}: {{A Multiscale Representation}} for {{Anti-Aliasing Neural Radiance Fields}}},
  shorttitle = {Mip-{{NeRF}}},
  booktitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Barron, Jonathan T. and Mildenhall, Ben and Tancik, Matthew and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P.},
  date = {2021-10},
  pages = {5835--5844},
  publisher = {IEEE},
  location = {Montreal, QC, Canada},
  doi = {10.1109/ICCV48922.2021.00580},
  url = {https://ieeexplore.ieee.org/document/9710056/},
  urldate = {2025-04-23},
  abstract = {The rendering procedure used by neural radiance fields (NeRF) samples a scene with a single ray per pixel and may therefore produce renderings that are excessively blurred or aliased when training or testing images observe scene content at different resolutions. The straightforward solution of supersampling by rendering with multiple rays per pixel is impractical for NeRF, because rendering each ray requires querying a multilayer perceptron hundreds of times. Our solution, which we call “mip-NeRF” (`a la “mipmap”), extends NeRF to represent the scene at a continuously-valued scale. By efficiently rendering anti-aliased conical frustums instead of rays, mip-NeRF reduces objectionable aliasing artifacts and significantly improves NeRF’s ability to represent fine details, while also being 7\% faster than NeRF and half the size. Compared to NeRF, mip-NeRF reduces average error rates by 17\% on the dataset presented with NeRF and by 60\% on a challenging multiscale variant of that dataset that we present. Mip-NeRF is also able to match the accuracy of a brute-force supersampled NeRF on our multiscale dataset while being 22× faster.},
  eventtitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-6654-2812-5},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/P5SZJNF8/Barron et al. - 2021 - Mip-NeRF A Multiscale Representation for Anti-Aliasing Neural Radiance Fields.pdf}
}

@article{bauer2024,
  title = {Photon {{Field Networks}} for {{Dynamic Real-Time Volumetric Global Illumination}}},
  author = {Bauer, David and Wu, Qi and Ma, Kwan-Liu},
  date = {2024-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {30},
  number = {1},
  pages = {975--985},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2023.3327107},
  url = {https://ieeexplore.ieee.org/document/10297590},
  urldate = {2025-05-13},
  abstract = {Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks—a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achieve interactive framerates even on large datasets. We conduct in-depth evaluations of the method's performance, including visual quality, stochastic noise, inference and rendering speeds, and accuracy regarding illumination and phase function awareness. Results are compared to ray marching, path tracing and photon mapping. Our findings show that Photon Field Networks can faithfully represent indirect global illumination within the boundaries of the trained phase spectrum while exhibiting less stochastic noise and rendering at a significantly faster rate than traditional methods.},
  keywords = {Data visualization,deep learning,global illumination,Light sources,Lighting,neural rendering,path tracing,Photonics,Real-time systems,Rendering (computer graphics),Visualization,Volume data,volume rendering,volume visualization},
  file = {/Users/julianstamm/Zotero/storage/WCS3UR6R/Bauer et al. - 2024 - Photon Field Networks for Dynamic Real-Time Volumetric Global Illumination.pdf;/Users/julianstamm/Zotero/storage/RMJ3ZGPB/10297590.html}
}

@online{benyoub2024,
  title = {{{VNDF}} Importance Sampling for an Isotropic {{Smith-GGX}} Distribution},
  author = {Benyoub, Anis},
  date = {2024-04-15T13:59:17+00:00},
  url = {https://auzaiffe.wordpress.com/2024/04/15/vndf-importance-sampling-an-isotropic-distribution/},
  urldate = {2024-08-28},
  abstract = {In this blog post, you will find an implementation for importance sampling a VNDF (GGX-Smith) isotropic distribution that is 15\% faster than the current state of the art and doesn’t require b…},
  langid = {english},
  organization = {A journey into rendering},
  keywords = {Important},
  file = {/Users/julianstamm/Zotero/storage/GL7VG6SL/vndf-importance-sampling-an-isotropic-distribution.html}
}

@online{blenderfoundation,
  title = {Sampling {{Patterns}} - {{Blender Developer Documentation}}},
  author = {{Blender Foundation}},
  url = {https://developer.blender.org/docs/features/cycles/sampling_patterns/},
  urldate = {2025-06-15},
  file = {/Users/julianstamm/Zotero/storage/ZJ4PLDZQ/sampling_patterns.html}
}

@unpublished{boksanksky,
  title = {Advancing {{Real-Time Path Tracing}} with {{Neural Radiance Cache}} | {{GTC Digital Spring}} 2023 | {{NVIDIA On-Demand}}},
  author = {Boksanksky, Jakub and Mihuț, Ana},
  url = {https://www.nvidia.com/en-us/on-demand/session/gtcspring23-s51967/},
  urldate = {2025-03-22},
  abstract = {We'll discuss the new Neural Radiance Cache (NRC) technology, AI-based radiance caching to rendering applications, based on research carried out at NVIDIA},
  langid = {american},
  file = {/Users/julianstamm/Zotero/storage/NYYXXH4B/Advancing Real-Time Path Tracing with Neural Radiance Cache  GTC Digital Spring 2023  NVIDIA On-De.pdf;/Users/julianstamm/Zotero/storage/XYNTXBG9/gtcspring23-s51967.html}
}

@inproceedings{burley2012,
  title = {Physically-{{Based Shading}} at {{Disney}}},
  booktitle = {Acm {{Siggraph}}},
  author = {Burley, Brent and {Walt Disney Animation Studios}},
  date = {2012},
  volume = {2012},
  number = {2012},
  pages = {1--7},
  publisher = {vol. 2012},
  url = {https://cw.fel.cvut.cz/b241/_media/courses/b4m39rso/lectures/s2012_pbs_disney_brdf_notes_v3.pdf},
  urldate = {2025-06-21},
  eventtitle = {{{SIGGRAPH}}},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/9NQM5I7N/Burley and Studios - 2012 - Physically-based shading at disney.pdf}
}

@article{burley2020,
  title = {Practical {{Hash-based Owen Scrambling}}},
  author = {Burley, Brent},
  date = {2020},
  journaltitle = {Journal of Computer Graphics Techniques},
  shortjournal = {JCGT},
  volume = {10},
  number = {4},
  pages = {29},
  url = {https://jcgt.org/published/0009/04/01/paper.pdf},
  abstract = {Owen’s nested uniform scrambling maximally randomizes low-discrepancy sequences while preserving multidimensional stratification. This enables advantageous convergence for favorable integrands and bounded error for unfavorable ones, and makes it less prone to structured artifacts than other scrambling methods. The Owen-scrambled Sobol sequence in particular has been gaining popularity recently in computer graphics. However, implementations typically use a precomputed table of samples which imposes limits on sequence length and dimension.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/KLRTTVCW/Burley - 2020 - Practical Hash-based Owen Scrambling.pdf}
}

@online{cao2016a,
  title = {Image {{Based Lighting}} in {{Offline}} and {{Real-time Rendering}}},
  author = {Cao, Jiayin},
  date = {2016-09-07T00:00:00+00:00},
  url = {https://agraphicsguynotes.com/posts/image_based_lighting_in_offline_and_realtime_rendering/},
  urldate = {2024-08-28},
  abstract = {Image-based lighting is a practical way to enhance the~visual quality of computer graphics. I used to be confused by it until I read the book “High Dynamic Range Imaging”, which provides a very clear explanation about IBL. And I actually have implemented the algorithm in my offline renderer before, it was just that I didn’t know it is IBL. The book PBRT has some materials talking about it without explicitly mentioning the term.},
  langid = {english},
  organization = {A GRAPHICS GUY'S NOTE},
  file = {/Users/julianstamm/Zotero/storage/XXEZUICZ/image_based_lighting_in_offline_and_realtime_rendering.html}
}

@article{chen2011,
  title = {Improved {{Stochastic Progressive Photon Mapping}} with {{Metropolis Sampling}}},
  author = {Chen, Jiating and Wang, Bin and Yong, Jun-Hai},
  date = {2011},
  journaltitle = {Computer Graphics Forum},
  volume = {30},
  number = {4},
  pages = {1205--1213},
  issn = {1467-8659},
  doi = {10.1111/j.1467-8659.2011.01979.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2011.01979.x},
  urldate = {2025-05-18},
  abstract = {This paper presents an improvement to the stochastic progressive photon mapping (SPPM), a method for robustly simulating complex global illumination with distributed ray tracing effects. Normally, similar to photon mapping and other particle tracing algorithms, SPPM would become inefficient when the photons are poorly distributed. An inordinate amount of photons are required to reduce the error caused by noise and bias to acceptable levels. In order to optimize the distribution of photons, we propose an extension of SPPM with a Metropolis-Hastings algorithm, effectively exploiting local coherence among the light paths that contribute to the rendered image. A well-designed scalar contribution function is introduced as our Metropolis sampling strategy, targeting at specific parts of image areas with large error to improve the efficiency of the radiance estimator. Experimental results demonstrate that the new Metropolis sampling based approach maintains the robustness of the standard SPPM method, while significantly improving the rendering efficiency for a wide range of scenes with complex lighting.},
  langid = {english},
  keywords = {I.3.3 Computer Graphics: Picture/Image Generation,I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism},
  file = {/Users/julianstamm/Zotero/storage/PM2HAMZI/j.1467-8659.2011.01979.html}
}

@online{cheng2021,
  title = {Go {{Small}} and {{Similar}}: {{A Simple Output Decay Brings Better Performance}}},
  shorttitle = {Go {{Small}} and {{Similar}}},
  author = {Cheng, Xuan and Xie, Tianshu and Wang, Xiaomin and Deng, Jiali and Liu, Minghui and Liu, Ming},
  date = {2021-06-12},
  eprint = {2106.06726},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.06726},
  url = {http://arxiv.org/abs/2106.06726},
  urldate = {2025-05-04},
  abstract = {Regularization and data augmentation methods have been widely used and become increasingly indispensable in deep learning training. Researchers who devote themselves to this have considered various possibilities. But so far, there has been little discussion about regularizing outputs of the model. This paper begins with empirical observations that better performances are significantly associated with output distributions, that have smaller average values and variances. By audaciously assuming there is causality involved, we propose a novel regularization term, called Output Decay, that enforces the model to assign smaller and similar output values on each class. Though being counter-intuitive, such a small modification result in a remarkable improvement on performance. Extensive experiments demonstrate the wide applicability, versatility, and compatibility of Output Decay.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/julianstamm/Zotero/storage/APRRMMY7/Cheng et al. - 2021 - Go Small and Similar A Simple Output Decay Brings Better Performance.pdf;/Users/julianstamm/Zotero/storage/8PJW58AD/2106.html}
}

@article{cigolle2014,
  title = {A {{Survey}} of {{Efﬁcient Representations}} for {{Independent Unit Vectors}}},
  author = {Cigolle, Zina H and Donow, Sam and Evangelakos, Daniel and Mara, Michael and McGuire, Morgan and Meyer, Quirin},
  date = {2014},
  journaltitle = {Journal of Computer Graphics Techniques},
  shortjournal = {Journal of Computer Graphics Techniques},
  volume = {3},
  number = {2},
  issn = {2331-7418},
  url = {https://jcgt.org/published/0003/02/01/paper-lowres.pdf},
  abstract = {The bandwidth cost and memory footprint of vector buffers are limiting factors for GPU rendering in many applications. This article surveys time-and space-efficient representations for the important case of non-register, in-core, statistically independent unit vectors, with emphasis on GPU encoding and decoding. These representations are appropriate for unit vectors in a geometry buffer or attribute stream—where no correlation between adjacent vectors is easily available—or for those in a normal map where quality higher than that of DXN is required. We do not address out-of-core and register storage vectors because they favor minimum-space and maximum-speed alternatives, respectively.},
  file = {/Users/julianstamm/Zotero/storage/INEEC6AN/Cigolle et al. - 2014 - A Survey of Efﬁcient Representations for Independent Unit Vectors.pdf;/Users/julianstamm/Zotero/storage/KZV4UPG7/Cigolle et al. - 2014 - A Survey of Efﬁcient Representations for Independent Unit Vectors.pdf}
}

@online{colbert,
  title = {Chapter 20. {{GPU-Based Importance Sampling}}},
  author = {Colbert, Mark and Křivánek, Jaroslav},
  url = {https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling},
  urldate = {2024-08-28},
  langid = {american},
  organization = {NVIDIA Developer},
  file = {/Users/julianstamm/Zotero/storage/25X6D5L2/chapter-20-gpu-based-importance-sampling.html}
}

@article{cook1982,
  title = {A {{Reflectance Model}} for {{Computer Graphics}}},
  author = {Cook, R. L. and Torrance, K. E.},
  date = {1982-01},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {1},
  number = {1},
  pages = {7--24},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/357290.357293},
  url = {https://dl.acm.org/doi/10.1145/357290.357293},
  urldate = {2024-02-23},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/KCIYIXWX/Cook and Torrance - 1982 - A Reflectance Model for Computer Graphics.pdf}
}

@article{cranley1976,
  title = {Randomization of {{Number Theoretic Methods}} for {{Multiple Integration}}},
  author = {Cranley, R. and Patterson, T. N. L.},
  date = {1976},
  journaltitle = {SIAM Journal on Numerical Analysis},
  volume = {13},
  number = {6},
  eprint = {2156452},
  eprinttype = {jstor},
  pages = {904--914},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1429},
  url = {https://www.jstor.org/stable/2156452},
  urldate = {2025-06-15},
  abstract = {A procedure is discussed for randomization of the number theoretic methods of the Korobov type producing stochastic families of multi-dimensional integration rules. These randomized rules have the advantage that confidence intervals can be given for the magnitude of error. The practical implementation is considered.}
}

@online{dereviannykh2024,
  title = {Neural {{Two-Level Monte Carlo Real-Time Rendering}}},
  author = {Dereviannykh, Mikhail and Klepikov, Dmitrii and Hanika, Johannes and Dachsbacher, Carsten},
  date = {2024-12-05},
  eprint = {2412.04634},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.04634},
  url = {http://arxiv.org/abs/2412.04634},
  urldate = {2025-05-10},
  abstract = {We introduce an efficient Two-Level Monte Carlo (subset of Multi-Level Monte Carlo, MLMC) estimator for real-time rendering of scenes with global illumination. Using MLMC we split the shading integral into two parts: the radiance cache integral and the residual error integral that compensates for the bias of the first one. For the first part, we developed the Neural Incident Radiance Cache (NIRC) leveraging the power of fully-fused tiny neural networks as a building block, which is trained on the fly. The cache is designed to provide a fast and reasonable approximation of the incident radiance: an evaluation takes 2-25x less compute time than a path tracing sample. This enables us to estimate the radiance cache integral with a high number of samples and by this achieve faster convergence. For the residual error integral, we compute the difference between the NIRC predictions and the unbiased path tracing simulation. Our method makes no assumptions about the geometry, materials, or lighting of a scene and has only few intuitive hyper-parameters. We provide a comprehensive comparative analysis in different experimental scenarios. Since the algorithm is trained in an on-line fashion, it demonstrates significant noise level reduction even for dynamic scenes and can easily be combined with other importance sampling schemes and noise reduction techniques.},
  pubstate = {prepublished},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Graphics},
  file = {/Users/julianstamm/Zotero/storage/V8LRZ6RQ/Dereviannykh et al. - 2024 - Neural Two-Level Monte Carlo Real-Time Rendering.pdf;/Users/julianstamm/Zotero/storage/TYAISTK5/2412.html}
}

@article{ding2023,
  title = {Approximate Global Illumination Using Photon Mapping: {{A}} Review},
  shorttitle = {Approximate Global Illumination Using Photon Mapping},
  author = {Ding, Haochen},
  date = {2023-12-31},
  journaltitle = {Highlights in Science, Engineering and Technology},
  shortjournal = {Highlights in Science, Engineering and Technology},
  volume = {76},
  pages = {799--813},
  doi = {10.54097/cja69975},
  abstract = {This paper introduces the two-step process of the standard photon mapping algorithm and a variety of other global biased illumination algorithms using photon mapping that have been proposed in recent years. Since there are many global biased illumination algorithms based on photon mapping, this review is a combination of these algorithms for the convenience of the reader, and the two-step process of standard PM will also be presented in this review to accommodate readers who are not familiar with the field. We will first introduce the specific implementation process and principles based on the two steps of PM, photon tracking and rendering, and then introduce a variety of polarized illumination techniques using photon maps, compare these methods and discuss the advantages, disadvantages, and applicability of each method in detail, and finally give a specific implementation of each method to give readers a clearer understanding of these methods. The final implementation of each method is shown to give the reader a clearer understanding of these methods.},
  file = {/Users/julianstamm/Zotero/storage/Y2FJ5JVL/Ding - 2023 - Approximate global illumination using photon mapping A review.pdf}
}

@inproceedings{dong2023,
  title = {Neural {{Parametric Mixtures}} for {{Path Guiding}}},
  booktitle = {Special {{Interest Group}} on {{Computer Graphics}} and {{Interactive Techniques Conference Conference Proceedings}}},
  author = {Dong, Honghao and Wang, Guoping and Li, Sheng},
  date = {2023-07-23},
  eprint = {2504.04315},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--10},
  doi = {10.1145/3588432.3591533},
  url = {http://arxiv.org/abs/2504.04315},
  urldate = {2025-05-10},
  abstract = {Previous path guiding techniques typically rely on spatial subdivision structures to approximate directional target distributions, which may cause failure to capture spatio-directional correlations and introduce parallax issue. In this paper, we present Neural Parametric Mixtures (NPM), a neural formulation to encode target distributions for path guiding algorithms. We propose to use a continuous and compact neural implicit representation for encoding parametric models while decoding them via lightweight neural networks. We then derive a gradient-based optimization strategy to directly train the parameters of NPM with noisy Monte Carlo radiance estimates. Our approach efficiently models the target distribution (incident radiance or the product integrand) for path guiding, and outperforms previous guiding methods by capturing the spatio-directional correlations more accurately. Moreover, our approach is more training efficient and is practical for parallelization on modern GPUs.},
  keywords = {Computer Science - Graphics},
  file = {/Users/julianstamm/Zotero/storage/5R9EESXN/Dong et al. - 2023 - Neural Parametric Mixtures for Path Guiding.pdf}
}

@online{dupuy,
  title = {Sampling {{Visible GGX Normals}} with {{Spherical Caps}}},
  author = {Dupuy, Jonathan},
  url = {https://gist.github.com/jdupuy/4c6e782b62c92b9cb3d13fbb0a5bd7a0},
  urldate = {2024-08-28},
  abstract = {Sampling Visible GGX Normals with Spherical Caps. GitHub Gist: instantly share code, notes, and snippets.},
  langid = {english},
  organization = {Gist},
  file = {/Users/julianstamm/Zotero/storage/N4SMYDIH/4c6e782b62c92b9cb3d13fbb0a5bd7a0.html}
}

@online{dupuy2023,
  title = {Sampling {{Visible GGX Normals}} with {{Spherical Caps}}},
  author = {Dupuy, Jonathan and Benyoub, Anis},
  date = {2023-06-12},
  eprint = {2306.05044},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.05044},
  urldate = {2024-08-28},
  abstract = {Importance sampling the distribution of visible GGX normals requires sampling those of a hemisphere. In this work, we introduce a novel method for sampling such visible normals. Our method builds upon the insight that a hemispherical mirror reflects parallel light rays uniformly within a solid angle shaped as a spherical cap. This spherical cap has the same apex as the hemispherical mirror, and its aperture given by the angle formed by the orientation of that apex and the direction of incident light rays. Based on this insight, we sample GGX visible normals as halfway vectors between a given incident direction and directions drawn from its associated spherical cap. Our resulting implementation is even simpler than that of Heitz and leads to up to systematic speed-ups in our benchmarks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Graphics},
  file = {/Users/julianstamm/Zotero/storage/4RQM7LNR/Dupuy and Benyoub - 2023 - Sampling Visible GGX Normals with Spherical Caps.pdf;/Users/julianstamm/Zotero/storage/W77TVJH5/2306.html}
}

@inproceedings{engelhardt2008,
  title = {Octahedron {{Environment Maps}}.},
  booktitle = {{{VMV}}},
  author = {Engelhardt, Thomas and Dachsbacher, Carsten},
  date = {2008},
  pages = {383--388},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=fcb9a6dbdf7b4c31f94e481cf101c83b73ea6410},
  urldate = {2024-12-21},
  file = {/Users/julianstamm/Zotero/storage/77HNC9NN/Engelhardt and Dachsbacher - 2008 - Octahedron Environment Maps..pdf}
}

@article{evangelou2021,
  title = {Fast {{Radius Search Exploiting Ray-Tracing Frameworks}}, {{JCGT}}},
  author = {Evangelou, Iordanis and Papaioannou, Georgios and Vardis, Konstantinos and Vasilakis, Andreas},
  date = {2021-02-05},
  volume = {10},
  pages = {2021},
  url = {https://jcgt.org/published/0010/01/02/},
  abstract = {Spatial queries to infer information from the neighborhood of a set of points are very frequently performed in rendering and geometry processing algorithms. Traditionally, these are accomplished using radius and k-nearest neighbors search operations, which utilize kd-trees and other specialized spatial data structures that fall short of delivering high performance. Recently, advances in ray tracing performance, with respect to both acceleration data structure construction and ray traversal times, have resulted in a wide adoption of the ray tracing paradigm for graphics-related tasks that spread beyond typical image synthesis. In this work, we propose an alternative formulation of the radius search operation that maps the problem to the ray tracing paradigm, in order to take advantage of the available GPU-accelerated solutions for it. We demonstrate the performance gain relative to traditional spatial search methods, especially on dynamically updated sample sets, using two representative applications: geometry processing point-wise operations on scanned point clouds and global illumination via progressive photon mapping.},
  file = {/Users/julianstamm/Zotero/storage/LYGE7YAG/Evangelou et al. - 2021 - Fast Radius Search Exploiting Ray-Tracing Frameworks, JCGT.pdf}
}

@article{frolov2012,
  title = {Irradiance {{Cache}} for a {{GPU Ray Tracer}}},
  author = {Frolov, Vladimir and Vostryakov, Konstantin and Kharlamov, Alexander and Galaktionov, V.},
  date = {2012-09-01},
  journaltitle = {GraphiCon'2012 conference proceedings},
  shortjournal = {GraphiCon'2012 conference proceedings},
  abstract = {Figure 1. The presented screenshots where rendered at 1920x1200 resolution on a GTX 560 HW under 5 minutes using Irradiance Caching (IC) technique. We achieved from 5 to 15 times acceleration compare to our naive path tracing implementation. Abstract This work proposes a GPU friendly irradiance caching (IC) solution, where performance critical parts of an irradiance cache algorithm are done completely on the GPU. We discuss some practical problems arising in the implementation of GPU irradiance caching, and propose solutions for them. The modified algorithm for the GPU is different from a CPU implementation in 2 ways. The first distinction is a multi-pass construction of irradiance cache followed by a final rendering stage and the second distinction is to insert a large record set at once instead of one by one, as used in traditional approaches. We also consider some details to efficiently implement look-up operations on the GPU.},
  file = {/Users/julianstamm/Zotero/storage/UEB2NTVI/Frolov et al. - 2012 - Irradiance Cache for a GPU Ray Tracer.pdf}
}

@online{fujii,
  title = {A Tiny Improvement of {{Oren-Nayar}} Reflectance Model},
  author = {Fujii, Yasuhiro},
  url = {https://mimosa-pudica.net/improved-oren-nayar.html},
  urldate = {2025-06-14},
  file = {/Users/julianstamm/Zotero/storage/W8I95P44/undefined}
}

@online{generatingraytracedcausticeffectsunrealengine4part12020,
  title = {Generating {{Ray-Traced Caustic Effects}} in {{Unreal Engine}} 4, {{Part}} 1},
  date = {2020-12-08T19:38:03+00:00},
  url = {https://developer.nvidia.com/blog/generating-ray-traced-caustic-effects-in-unreal-engine-4-part-1/},
  urldate = {2025-05-18},
  abstract = {Caustics are common optical phenomenon in the real world. From the sloshing sparkles by water surfaces to the curved highlights in the backlight of clear glass, they are everywhere. However…},
  langid = {american},
  organization = {NVIDIA Technical Blog}
}

@article{georgiev2012,
  title = {Light Transport Simulation with Vertex Connection and Merging},
  author = {Georgiev, Iliyan and Křivánek, Jaroslav and Davidovič, Tomáš and Slusallek, Philipp},
  date = {2012-11},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {31},
  number = {6},
  pages = {1--10},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2366145.2366211},
  url = {https://dl.acm.org/doi/10.1145/2366145.2366211},
  urldate = {2025-05-18},
  abstract = {Developing robust light transport simulation algorithms that are capable of dealing with arbitrary input scenes remains an elusive challenge. Although efficient global illumination algorithms exist, an acceptable approximation error in a reasonable amount of time is usually only achieved for specific types of input scenes. To address this problem, we present a reformulation of photon mapping as a bidirectional path sampling technique for Monte Carlo light transport simulation. The benefit of our new formulation is twofold. First, it makes it possible, for the first time, to explain in a formal manner the relative efficiency of photon mapping and bidirectional path tracing, which have so far been considered conceptually incompatible solutions to the light transport problem. Second, it allows for a seamless integration of the two methods into a more robust combined rendering algorithm via multiple importance sampling. A progressive version of this algorithm is consistent and efficiently handles a wide variety of lighting conditions, ranging from direct illumination, diffuse and glossy inter-reflections, to specular-diffusespecular light transport. Our analysis shows that this algorithm inherits the high asymptotic performance from bidirectional path tracing for most light path types, while benefiting from the efficiency of photon mapping for specular-diffuse-specular lighting effects.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/MZXA4C7C/Georgiev et al. - 2012 - Light transport simulation with vertex connection and merging.pdf;/Users/julianstamm/Zotero/storage/35FI9KHH/VertexMerging.html}
}

@article{greger1998,
  title = {The Irradiance Volume},
  author = {Greger, G. and Shirley, P. and Hubbard, P.M. and Greenberg, D.P.},
  year = {March-April/1998},
  journaltitle = {IEEE Computer Graphics and Applications},
  shortjournal = {IEEE Comput. Grap. Appl.},
  volume = {18},
  number = {2},
  pages = {32--43},
  issn = {02721716},
  doi = {10.1109/38.656788},
  url = {http://ieeexplore.ieee.org/document/656788/},
  urldate = {2025-04-22},
  file = {/Users/julianstamm/Zotero/storage/JJEZB4CW/The irradiance volume.pdf;/Users/julianstamm/Zotero/storage/RFQNFDU2/mcg1998020032.pdf}
}

@article{gunther,
  title = {Realtime {{Caustics Using Distributed Photon Mapping}}},
  author = {Günther, Johannes and Wald, Ingo and Slusallek, Philipp},
  abstract = {With the advancements in realtime ray tracing and new global illumination algorithms we are now able to render the most important illumination effects at interactive rates. One of the major remaining issues is the fast and efficient simulation of caustic illumination, such as e.g. the illumination from a car headlight. The photon mapping algorithm is a simple and robust approach that generates high-quality results and is the preferred algorithm for computing caustic illumination. However, photon mapping has a number of properties that make it rather slow on today’s processors. Photon mapping has also been notoriously difficult to parallelize efficiently.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/Q88BQMKN/Günther et al. - Realtime Caustics Using Distributed Photon Mapping.pdf}
}

@article{hachisuka2008,
  title = {Progressive Photon Mapping},
  author = {Hachisuka, Toshiya and Ogaki, Shinji and Jensen, Henrik Wann},
  date = {2008-12-01},
  journaltitle = {ACM Trans. Graph.},
  volume = {27},
  number = {5},
  pages = {130:1--130:8},
  issn = {0730-0301},
  doi = {10.1145/1409060.1409083},
  url = {https://dl.acm.org/doi/10.1145/1409060.1409083},
  urldate = {2025-05-13},
  abstract = {This paper introduces a simple and robust progressive global illumination algorithm based on photon mapping. Progressive photon mapping is a multi-pass algorithm where the first pass is ray tracing followed by any number of photon tracing passes. Each photon tracing pass results in an increasingly accurate global illumination solution that can be visualized in order to provide progressive feedback. Progressive photon mapping uses a new radiance estimate that converges to the correct radiance value as more photons are used. It is not necessary to store the full photon map, and unlike standard photon mapping it possible to compute a global illumination solution with any desired accuracy using a limited amount of memory. Compared with existing Monte Carlo ray tracing methods progressive photon mapping provides an efficient and robust alternative in the presence of complex light transport such as caustics and in particular reflections of caustics.},
  file = {/Users/julianstamm/Zotero/storage/K5CVIX5T/Hachisuka et al. - 2008 - Progressive photon mapping.pdf;/Users/julianstamm/Zotero/storage/PXUM7QZ3/Hachisuka et al. - Progressive Photon Mapping.pdf}
}

@inproceedings{hachisuka2009a,
  title = {Stochastic Progressive Photon Mapping},
  booktitle = {{{ACM SIGGRAPH Asia}} 2009 Papers},
  author = {Hachisuka, Toshiya and Jensen, Henrik Wann},
  date = {2009-12-01},
  series = {{{SIGGRAPH Asia}} '09},
  pages = {1--8},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1661412.1618487},
  url = {https://dl.acm.org/doi/10.1145/1661412.1618487},
  urldate = {2025-05-13},
  abstract = {This paper presents a simple extension of progressive photon mapping for simulating global illumination with effects such as depth-of-field, motion blur, and glossy reflections. Progressive photon mapping is a robust global illumination algorithm that can handle complex illumination settings including specular-diffuse-specular paths. The algorithm can compute the correct radiance value at a point in the limit. However, progressive photon mapping is not effective at rendering distributed ray tracing effects, such as depth-of-field, that requires multiple pixel samples in order to compute the correct average radiance value over a region. In this paper, we introduce a new formulation of progressive photon mapping, called stochastic progressive photon mapping, which makes it possible to compute the correct average radiance value for a region. The key idea is to use shared photon statistics within the region rather than isolated photon statistics at a point. The algorithm is easy to implement, and our results demonstrate how it efficiently handles scenes with distributed ray tracing effects, while maintaining the robustness of progressive photon mapping in scenes with complex lighting.},
  isbn = {978-1-60558-858-2},
  file = {/Users/julianstamm/Zotero/storage/B483Y8QF/Hachisuka and Jensen - 2009 - Stochastic progressive photon mapping.pdf}
}

@inproceedings{hachisuka2010,
  title = {Parallel Progressive Photon Mapping on {{GPUs}}},
  booktitle = {{{ACM SIGGRAPH ASIA}} 2010 {{Sketches}}},
  author = {Hachisuka, Toshiya and Jensen, Henrik Wann},
  date = {2010-12-15},
  series = {{{SA}} '10},
  pages = {1},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1899950.1900004},
  url = {https://dl.acm.org/doi/10.1145/1899950.1900004},
  urldate = {2025-05-13},
  abstract = {Accurate global illumination rendering using GPUs is gaining attention because of the highly parallel nature of global illumination algorithms. For example, computing the radiance of each pixel using path tracing is embarrassingly parallel. Some major commercial rendering software also started adopting global illumination on GPUs.},
  isbn = {978-1-4503-0523-5},
  file = {/Users/julianstamm/Zotero/storage/CSY6HFUG/Hachisuka and Jensen - 2010 - Parallel progressive photon mapping on GPUs.pdf}
}

@article{heckbert1990,
  title = {Adaptive Radiosity Textures for Bidirectional Ray Tracing},
  author = {Heckbert, Paul S.},
  date = {1990-09},
  journaltitle = {ACM SIGGRAPH Computer Graphics},
  shortjournal = {SIGGRAPH Comput. Graph.},
  volume = {24},
  number = {4},
  pages = {145--154},
  issn = {0097-8930},
  doi = {10.1145/97880.97895},
  url = {https://dl.acm.org/doi/10.1145/97880.97895},
  urldate = {2025-04-24},
  abstract = {We present a rendering method designed to provide accurate, general simulation of global illumination for realistic image synthesis. Separating surface interaction into diffuse plus specular, we compute the specular component on the fly, as in ray tracing, and store the diffuse component (the radiosity) for later-reuse, similar to a radiosity algorithm. Radiosities are stored in               adaptive radiosity textures (rexes               )               1               that record the pattern of light and shadow on every diffuse surface in the scene. They adaptively subdivide themselves to the appropriate level of detail for the picture being made, resolving sharp shadow edges automatically.We use a three-pass, bidirectional ray tracing algorithm that traces rays from both the lights and the eye. The "size pass" records visibility information on diffuse surfaces; the "light pass" progressively traces rays from lights and bright surfaces to deposit photons on diffuse surfaces to construct the radiosity textures; and the "eye pass" traces rays from the eye, collecting light from diffuse surfaces to make a picture.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/9LMSPYEB/Heckbert - 1990 - Adaptive radiosity textures for bidirectional ray tracing.pdf}
}

@article{heinrich1994,
  title = {Quasi-{{Monte Carlo Methods}} in {{Computer Graphics Part II}}: {{The Radiance Equation}}},
  shorttitle = {Quasi-{{Monte Carlo Methods}} in {{Computer Graphics Part II}}},
  author = {Heinrich, Stefan and Keller, Alexander},
  date = {1994},
  journaltitle = {Interner Bericht},
  volume = {243},
  pages = {94},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=c7420a077ac9ffc31b22f07366132432df9ae046},
  urldate = {2025-06-21}
}

@report{heinrich1994a,
  title = {Quasi-{{Monte Carlo Methods}} in {{Computer Graphics}}, {{Part I}}: {{The QMC-Bu}} Er},
  shorttitle = {Quasi-{{Monte Carlo Methods}} in {{Computer Graphics}}, {{Part I}}},
  author = {Heinrich, Stefan and Keller, Alexander},
  date = {1994},
  institution = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f9a420d0c5739e48b82f4eb7ab9e017f4e7eb658},
  urldate = {2025-06-21}
}

@article{heitz2014,
  title = {Understanding the {{Masking-Shadowing Function}} in {{Microfacet-Based BRDFs}}},
  author = {Heitz, Eric},
  date = {2014},
  volume = {3},
  number = {2},
  abstract = {We provide a new presentation of the masking-shadowing functions (or geometric attenuation factors) in microfacet-based BRDFs and answer some common questions about their applications. Our main motivation is to define a correct (geometrically indicated), physically based masking function for application in microfacet models, as well as the properties that function should exhibit. Indeed, several different masking functions are often presented in the literature and making the right choice is not always obvious. We start by showing that physically based masking functions are constrained by the projected area of the visible microsurface onto the outgoing direction. We use this property to derive the distribution of visible normals from the microsurface, whose normalization factor is the masking function. We then show how the common form of microfacet-based BRDFs emerges from this distribution. As a consequence, the masking function is related to the correct normalization of microfacetbased BRDFs. However, while the correct masking function satisfies these normalization constraints, its explicit form is can only be determined for a given microsurface profile.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/4XF7GXY4/Heitz - 2014 - Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs.pdf}
}

@article{heitz2014a,
  title = {Importance {{Sampling Microfacet}}‐{{Based BSDFs}} Using the {{Distribution}} of {{Visible Normals}}},
  author = {Heitz, E. and family=Eon, given=E., prefix=d', useprefix=true},
  date = {2014-07},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {33},
  number = {4},
  pages = {103--112},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.12417},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.12417},
  urldate = {2025-05-23},
  abstract = {Abstract             We present a new approach to microfacet‐based BSDF importance sampling. Previously proposed sampling schemes for popular analytic BSDFs typically begin by choosing a microfacet normal at random in a way that is independent of direction of incident light. To sample the full BSDF using these normals requires arbitrarily large sample weights leading to possible fireflies. Additionally, at grazing angles nearly half of the sampled normals face away from the incident ray and must be rejected, making the sampling scheme inefficient. Instead, we show how to use the distribution of visible normals directly to generate samples, where normals are weighted by their projection factor toward the incident direction. In this way, no backfacing normals are sampled and the sample weights contain only the shadowing factor of outgoing rays (and additionally a Fresnel term for conductors). Arbitrarily large sample weights are avoided and variance is reduced. Since the BSDF depends on the microsurface model, we describe our sampling algorithm for two models: the V‐cavity and the Smith models. We demonstrate results for both isotropic and anisotropic rough conductors and dielectrics with Beckmann and GGX distributions.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/CIY8DU66/Heitz and d'Eon - 2014 - Importance Sampling Microfacet‐Based BSDFs using the Distribution of Visible Normals.pdf}
}

@article{heitz2018,
  title = {Sampling the {{GGX Distribution}} of {{Visible Normals}}},
  author = {Heitz, Eric},
  date = {2018},
  journaltitle = {Journal of Computer Graphics Techniques},
  shortjournal = {JCGT},
  volume = {7},
  number = {4},
  abstract = {Importance sampling microfacet bidirectional scattering distribution functions (BSDFs) using their distribution of visible normals (VNDF) yields significant variance reduction in Monte Carlo rendering. In this article, we describe an efficient and exact sampling routine for the VNDF of the GGX microfacet distribution. This routine leverages the property that GGX is the distribution of normals of a truncated ellipsoid, and sampling the GGX VNDF is equivalent to sampling the 2D projection of this truncated ellipsoid. To do that, we simplify the problem by using the linear transformation that maps the truncated ellipsoid to a hemisphere. Since linear transformations preserve the uniformity of projected areas, sampling in the hemisphere configuration and transforming the samples back to the ellipsoid configuration yields valid samples from the GGX VNDF.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/QC7SR6WD/Heitz - 2018 - Sampling the GGX Distribution of Visible Normals.pdf}
}

@article{hery2013,
  title = {Physically Based Lighting at Pixar},
  author = {Hery, Christophe and Villemin, Ryusuke and Studios, Pixar Animation},
  date = {2013},
  journaltitle = {Physically Based Shading’SIGGRAPH Course},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0c614421eeb49d910613b75641b766a96f6a9e32},
  urldate = {2025-06-21},
  file = {/Users/julianstamm/Zotero/storage/57836DJR/Hery et al. - 2013 - Physically based lighting at pixar.pdf}
}

@article{hoetzlein,
  title = {{{INTERACTIVE MILLION-PARTICLE FLUIDS}}},
  author = {Hoetzlein, Rama C and Devtech, Graphics},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/8L9DW5LI/Hoetzlein and Devtech - INTERACTIVE MILLION-PARTICLE FLUIDS.pdf}
}

@software{horizonresearchrtnn2025,
  title = {Horizon-Research/Rtnn},
  date = {2025-05-19T01:31:53Z},
  origdate = {2021-06-18T00:32:22Z},
  url = {https://github.com/horizon-research/rtnn},
  urldate = {2025-05-27},
  organization = {horizon-research}
}

@online{improveshaderperformanceingameframeratesshaderexecutionreordering2022,
  title = {Improve {{Shader Performance}} and {{In-Game Frame Rates}} with {{Shader Execution Reordering}}},
  date = {2022-10-13T00:01:30+00:00},
  url = {https://developer.nvidia.com/blog/improve-shader-performance-and-in-game-frame-rates-with-shader-execution-reordering/},
  urldate = {2025-05-18},
  abstract = {Learn about Shader Execution Reordering (SER), a performance optimization that unlocks the potential for better ray and memory coherency in ray tracing shaders.},
  langid = {american},
  organization = {NVIDIA Technical Blog}
}

@incollection{jensen1996,
  title = {Global {{Illumination}} Using {{Photon Maps}}},
  booktitle = {Rendering {{Techniques}} ’96},
  author = {Jensen, Henrik Wann},
  editor = {Pueyo, Xavier and Schröder, Peter},
  date = {1996},
  pages = {21--30},
  publisher = {Springer Vienna},
  location = {Vienna},
  doi = {10.1007/978-3-7091-7484-5_3},
  url = {http://link.springer.com/10.1007/978-3-7091-7484-5_3},
  urldate = {2025-04-22},
  abstract = {This paper presents a two pass global illumination method based on the concept of photon maps. It represents a significant improvement of a previously described approach both with respect to speed, accuracy and versatility. In the first pass two photon maps are created by emitting packets of energy (photons) from the light sources and storing these as they hit surfaces within the scene. We use one high resolution caustics photon map to render caustics that are visualized directly and one low resolution photon map that is used during the rendering step. The scene is rendered using a distribution ray tracing algorithm optimized by using the information in the photon maps. Shadow photons are used to render shadows more efficiently and the directional information in the photon map is used to generate optimized sampling directions and to limit the recursion in the distribution ray tracer by providing an estimate of the radiance on all surfaces with the exception of specular and highly glossy surfaces.},
  isbn = {978-3-211-82883-0 978-3-7091-7484-5},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/YK6TW69L/Jensen - 1996 - Global Illumination using Photon Maps.pdf}
}

@book{jensen2010,
  title = {Realistic Image Synthesis Using Photon Mapping},
  author = {Jensen, Henrik Wann},
  date = {2010},
  edition = {Nachdr.},
  publisher = {Peters},
  location = {Wellesley, Mass},
  isbn = {978-1-56881-147-5 978-1-56881-462-9},
  langid = {english},
  pagetotal = {181},
  file = {/Users/julianstamm/Zotero/storage/5J77UPC8/Jensen - 2010 - Realistic image synthesis using photon mapping.pdf}
}

@article{jones2014,
  title = {{{IRRADIANCE CACHING FOR GLOBAL ILLUMINATION CALCULATION ON GRAPHICS HARDWARE}}},
  author = {Jones, Nathaniel L and Reinhart, Christoph F},
  date = {2014},
  abstract = {Recent developments in integrated circuit technology tend toward increased numbers of cores rather than faster clock speeds, so software must use parallelism to achieve faster run times. The ray tracing performed by Radiance is highly parallelizable in concept, with the exception of irradiance caching that serially stores and retrieves results of expensive indirect irradiation computations. This paper describes a novel method of parallel irradiance caching for global illumination on a graphics processing unit (GPU).},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/3WP8WKRP/Jones and Reinhart - 2014 - IRRADIANCE CACHING FOR GLOBAL ILLUMINATION CALCULATION ON GRAPHICS HARDWARE.pdf}
}

@inproceedings{kajiya1986,
  title = {The Rendering Equation},
  booktitle = {Proceedings of the 13th Annual Conference on {{Computer}} Graphics and Interactive Techniques},
  author = {Kajiya, James T.},
  date = {1986-08-31},
  series = {{{SIGGRAPH}} '86},
  pages = {143--150},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/15922.15902},
  url = {https://dl.acm.org/doi/10.1145/15922.15902},
  urldate = {2024-02-23},
  abstract = {We present an integral equation which generalizes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting rendering algorithm extends the range of optical phenomena which can be effectively simulated.},
  isbn = {978-0-89791-196-2},
  keywords = {Important},
  file = {/Users/julianstamm/Zotero/storage/WZRDDU9X/Kajiya - 1986 - The rendering equation.pdf}
}

@article{kang2016,
  title = {A Survey of Photon Mapping State-of-the-Art Research and Future Challenges},
  author = {Kang, Chun-meng and Wang, Lu and Xu, Yan-ning and Meng, Xiang-xu},
  date = {2016-03-01},
  journaltitle = {Frontiers of Information Technology \& Electronic Engineering},
  shortjournal = {Frontiers Inf Technol Electronic Eng},
  volume = {17},
  number = {3},
  pages = {185--199},
  issn = {2095-9230},
  doi = {10.1631/FITEE.1500251},
  url = {https://doi.org/10.1631/FITEE.1500251},
  urldate = {2025-05-18},
  abstract = {Global illumination is the core part of photo-realistic rendering. The photon mapping algorithm is an effective method for computing global illumination with its obvious advantage of caustic and color bleeding rendering. It is an active research field that has been developed over the past two decades. The deficiency of precise details and efficient rendering are still the main challenges of photon mapping. This report reviews recent work and classifies it into a set of categories including radiance estimation, photon relaxation, photon tracing, progressive photon mapping, and parallel methods. The goals of our report are giving readers an overall introduction to photon mapping and motivating further research to address the limitations of existing methods.},
  langid = {english},
  keywords = {3-D Image Reconstruction,Applied Optics,Bioluminescence Imaging,Brain Mapping,Fluorescence Imaging,Global illumination,Multiphoton microscopy,Photon mapping,Photon relaxation,Progressive photon mapping,Radiance estimation,TP37},
  file = {/Users/julianstamm/Zotero/storage/Q9FH8HRW/Kang et al. - 2016 - A survey of photon mapping state-of-the-art research and future challenges.pdf}
}

@article{kaplanyan2013,
  title = {Adaptive Progressive Photon Mapping},
  author = {Kaplanyan, Anton S. and Dachsbacher, Carsten},
  date = {2013-04-30},
  journaltitle = {ACM Trans. Graph.},
  volume = {32},
  number = {2},
  pages = {16:1--16:13},
  issn = {0730-0301},
  doi = {10.1145/2451236.2451242},
  url = {https://dl.acm.org/doi/10.1145/2451236.2451242},
  urldate = {2025-05-18},
  abstract = {This article introduces a novel locally adaptive progressive photon mapping technique which optimally balances noise and bias in rendered images to minimize the overall error. It is the result of an analysis of the radiance estimation in progressive photon mapping. As a first step, we establish a connection to the field of recursive estimation and regression in statistics and derive the optimal estimation parameters for the asymptotic convergence of existing approaches. Next, we show how to reformulate photon mapping as a spatial regression in the measurement equation of light transport. This reformulation allows us to derive a novel data-driven bandwidth selection technique for estimating a pixel's measurement. The proposed technique possesses attractive convergence properties with finite numbers of samples, which is important for progressive rendering, and it also provides better results for quasi-converged images. Our results show the practical benefits of using our adaptive method.},
  file = {/Users/julianstamm/Zotero/storage/J7LKN8V3/Kaplanyan and Dachsbacher - 2013 - Adaptive progressive photon mapping.pdf}
}

@incollection{keller1995,
  title = {A {{Quasi-Monte Carlo Algorithm}} for the {{Global Illumination Problem}} in the {{Radiosity Setting}}},
  booktitle = {Monte {{Carlo}} and {{Quasi-Monte Carlo Methods}} in {{Scientific Computing}}},
  author = {Keller, Alexander},
  editor = {Niederreiter, Harald and Shiue, Peter Jau-Shyong},
  editora = {Bickel, P. and Diggle, P. and Fienberg, S. and Krickeberg, K. and Olkin, I. and Wermuth, N. and Zeger, S.},
  editoratype = {redactor},
  date = {1995},
  volume = {106},
  pages = {239--251},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4612-2552-2_15},
  url = {http://link.springer.com/10.1007/978-1-4612-2552-2_15},
  urldate = {2025-06-21},
  isbn = {978-0-387-94577-4 978-1-4612-2552-2},
  file = {/Users/julianstamm/Zotero/storage/ZFT5XLAD/Keller - 1995 - A Quasi-Monte Carlo Algorithm for the Global Illumination Problem in the Radiosity Setting.pdf}
}

@incollection{keller1996,
  title = {Quasi-{{Monte Carlo Radiosity}}},
  booktitle = {Rendering {{Techniques}} ’96},
  author = {Keller, Alexander},
  editor = {Pueyo, Xavier and Schröder, Peter},
  date = {1996},
  pages = {101--110},
  publisher = {Springer Vienna},
  location = {Vienna},
  doi = {10.1007/978-3-7091-7484-5_11},
  url = {http://link.springer.com/10.1007/978-3-7091-7484-5_11},
  urldate = {2025-06-21},
  isbn = {978-3-211-82883-0 978-3-7091-7484-5},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/4K86PPHB/Keller - 1996 - Quasi-Monte Carlo Radiosity.pdf}
}

@article{keller1996a,
  title = {Quasi-{{Monte Carlo}} Methods in Computer Graphics: The Global Illumination Problem},
  shorttitle = {Quasi-{{Monte Carlo}} Methods in Computer Graphics},
  author = {Keller, Alexander},
  date = {1996},
  journaltitle = {LECTURES IN APPLIED MATHEMATICS-AMERICAN MATHEMATICAL SOCIETY},
  volume = {32},
  pages = {455--470},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=579bca8c938f1e0f25474a02a4ff93f5b6ea8886},
  urldate = {2025-06-21},
  file = {/Users/julianstamm/Zotero/storage/T3L6VFAD/Keller - 1996 - Quasi-Monte Carlo methods in computer graphics the global illumination problem.pdf}
}

@book{kern2024,
  title = {{{ReSTIR FG}}: {{Real-Time Reservoir Resampled Photon Final Gathering}}},
  shorttitle = {{{ReSTIR FG}}},
  author = {Kern, René and Brüll, Felix and Grosch, Thorsten},
  date = {2024},
  publisher = {The Eurographics Association},
  issn = {1727-3463},
  url = {https://doi.org/10.2312/sr.20241155},
  urldate = {2025-05-13},
  abstract = {Achieving real-time global illumination for a given scene remains challenging, even with the advent of hardware ray tracing, due to the substantial quantity of rays required. To enhance the quality of the limited number of samples, spatial and temporal resampling can be used. The concept of resampling gained popularity with ReSTIR DI [BWP*20], enabling real-time direct illumination for scenes with millions of lights. This concept was further extended by combining it with path tracing to quickly approximate the indirect illumination (ReSTIR GI [OLK*21]) or correctly approximate global illumination (ReSTIR PT [LKB*22] and Suffix ReSTIR [KLR*23]). However, these algorithms fall short in effectively rendering caustic effects -bundles of reflected or refracted light- often associated with photon mapping. We introduce ReSTIR FG, an efficient real time indirect illumination algorithm that combines photon final gathering with the principles of ReSTIR. First, we introduce an efficient photon final gathering scheme, enabling quick consistent offline rendering. Then we combine our photon final gathering with spatiotemporal resampling to allow for real time global illumination. Our algorithm is capable of displaying multi bounce indirect illumination, as well as caustic effects, while remaining competitive in both runtime and quality when compared to the aforementioned state-of-the-art global illumination resampling techniques.},
  isbn = {978-3-03868-262-2},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/3SNITWFA/Kern et al. - 2024 - ReSTIR FG Real-Time Reservoir Resampled Photon Final Gathering.pdf;/Users/julianstamm/Zotero/storage/U7H4ZJMG/Kern et al. - 2024 - ReSTIR FG Real-Time Reservoir Resampled Photon Final Gathering.pdf}
}

@report{kirkpatrick2025,
  title = {Web {{Content Accessibility Guidelines}} ({{WCAG}}) 2.1},
  shorttitle = {{{WCAG}}},
  author = {Kirkpatrick, Andrew and O Connor, Joshue and Campbell, Alastair and Cooper, Michael},
  date = {2025-05-06},
  institution = {World Wide Web Consortium},
  url = {https://www.w3.org/TR/WCAG21/#dfn-relative-luminance},
  urldate = {2025-06-21},
  file = {/Users/julianstamm/Zotero/storage/4KUYZ5CJ/WCAG21.html}
}

@book{krivanek2022,
  title = {Practical {{Global Illumination}} with {{Irradiance Caching}}},
  author = {Krivanek, Jaroslav and Gautron, Pascal},
  date = {2022-05-31},
  eprint = {Z4JyEAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Springer Nature},
  abstract = {Irradiance caching is a ray tracing-based technique for computing global illumination on diffuse surfaces. Specifically, it addresses the computation of indirect illumination bouncing off one diffuse object onto another. The sole purpose of irradiance caching is to make this computation reasonably fast. The main idea is to perform the indirect illumination sampling only at a selected set of locations in the scene, store the results in a cache, and reuse the cached value at other points through fast interpolation. This book is for anyone interested in making a production-ready implementation of irradiance caching that reliably renders artifact-free images. Since its invention 20 years ago, the irradiance caching algorithm has been successfully used to accelerate global illumination computation in the Radiance lighting simulation system. Its widespread use had to wait until computers became fast enough to consider global illumination in film production rendering. Since then, its use is ubiquitous. Virtually all commercial and open-source rendering software base the global illumination computation upon irradiance caching. Although elegant and powerful, the algorithm in its basic form often fails to produce artifact-free mages. Unfortunately, practical information on implementing the algorithm is scarce. The main objective of this book is to show the irradiance caching algorithm along with all the details and tricks upon which the success of its practical implementation is dependent. In addition, we discuss some extensions of the basic algorithm, such as a GPU implementation for interactive global illumination computation and temporal caching that exploits temporal coherence to suppress flickering in animations. Our goal is to show the material without being overly theoretical. However, the reader should have some basic understanding of rendering concepts, ray tracing in particular. Familiarity with global illumination is useful but not necessary to read this book. Table of Contents: Introduction to Ray Tracing and Global Illumination / Irradiance Caching Core / Practical Rendering with Irradiance Caching / Irradiance Caching in a Complete Global Illumination / Irradiance Caching on Graphics Hardware / Temporal Irradiance Caching},
  isbn = {978-3-031-79540-4},
  langid = {english},
  pagetotal = {144},
  keywords = {Computers / Artificial Intelligence / Computer Vision & Pattern Recognition,Computers / Image Processing,Computers / Optical Data Processing,Mathematics / General}
}

@article{lagarde,
  title = {Moving {{Frostbite}} to {{Physically Based Rendering}} 3.0},
  author = {Lagarde, Sébastien and family=Rousiers, given=Charles, prefix=de, useprefix=true},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/N4P276LI/s2014_pbs_frostbite_slides.pdf;/Users/julianstamm/Zotero/storage/Q5HSZPJR/Lagarde and de Rousiers - Moving Frostbite to Physically Based Rendering 3.0.pdf}
}

@online{lagarde2017,
  title = {Physically {{Based Material Where Are We}}},
  author = {Lagarde, Sébastien},
  date = {2017},
  url = {https://openproblems.realtimerendering.com/s2017/02-PhysicallyBasedMaterialWhereAreWe.pdf},
  urldate = {2025-04-29},
  file = {/Users/julianstamm/Zotero/storage/C5BT57M4/Physically Based Material Where Are We.pdf}
}

@article{lin2022,
  title = {Generalized Resampled Importance Sampling: Foundations of {{ReSTIR}}},
  shorttitle = {Generalized Resampled Importance Sampling},
  author = {Lin, Daqi and Kettunen, Markus and Bitterli, Benedikt and Pantaleoni, Jacopo and Yuksel, Cem and Wyman, Chris},
  date = {2022-07},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {41},
  number = {4},
  pages = {1--23},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3528223.3530158},
  url = {https://dl.acm.org/doi/10.1145/3528223.3530158},
  urldate = {2025-04-30},
  abstract = {As scenes become ever more complex and real-time applications embrace ray tracing, path sampling algorithms that maximize quality at low sample counts become vital. Recent               resampling               algorithms building on Talbot et al.'s [2005] resampled importance sampling (RIS) reuse paths spatiotemporally to render surprisingly complex light transport with a few samples per pixel. These reservoir-based spatiotemporal importance resamplers (ReSTIR) and their underlying RIS theory make various assumptions, including sample independence. But sample reuse               introduces correlation               , so ReSTIR-style iterative reuse loses most convergence guarantees that RIS theoretically provides.                          We introduce generalized resampled importance sampling (GRIS) to extend the theory, allowing RIS on correlated samples, with unknown PDFs and taken from varied domains. This solidifies the theoretical foundation, allowing us to derive variance bounds and convergence conditions in ReSTIR-based samplers. It also guides practical algorithm design and enables advanced path reuse between pixels via complex shift mappings.             We show a path-traced resampler (ReSTIR PT) running interactively on complex scenes, capturing many-bounce diffuse and specular lighting while shading just one path per pixel. With our new theoretical foundation, we can also modify the algorithm to guarantee convergence for offline renderers.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/3GP57JFU/Lin et al. - 2022 - Generalized resampled importance sampling foundations of ReSTIR.pdf}
}

@inproceedings{magdon-ismail1998,
  title = {Neural {{Networks}} for {{Density Estimation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Magdon-Ismail, Malik and Atiya, Amir},
  date = {1998},
  volume = {11},
  publisher = {MIT Press},
  url = {https://proceedings.neurips.cc/paper_files/paper/1998/hash/9327969053c0068dd9e07c529866b94d-Abstract.html},
  urldate = {2025-05-04},
  abstract = {We  introduce two  new  techniques for  density estimation.  Our ap(cid:173) proach poses the problem as  a  supervised learning task which  can  be  performed  using  Neural  Networks.  We  introduce  a  stochas(cid:173) tic method for  learning the cumulative distribution  and an  analo(cid:173) gous  deterministic technique.  We  demonstrate convergence of our  methods  both theoretically and experimentally, and provide com(cid:173) parisons with the Parzen estimate.  Our theoretical results demon(cid:173) strate better convergence properties than the Parzen estimate.},
  file = {/Users/julianstamm/Zotero/storage/9636C9J9/Magdon-Ismail and Atiya - 1998 - Neural Networks for Density Estimation.pdf}
}

@inproceedings{mara2013,
  title = {Toward Practical Real-Time Photon Mapping: Efficient {{GPU}} Density Estimation},
  shorttitle = {Toward Practical Real-Time Photon Mapping},
  booktitle = {Proceedings of the {{ACM SIGGRAPH Symposium}} on {{Interactive 3D Graphics}} and {{Games}}},
  author = {Mara, Michael and Luebke, David and McGuire, Morgan},
  date = {2013-03-21},
  series = {{{I3D}} '13},
  pages = {71--78},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2448196.2448207},
  url = {https://dl.acm.org/doi/10.1145/2448196.2448207},
  urldate = {2025-05-17},
  abstract = {We describe the design space for real-time photon density estimation, the key step of rendering global illumination (GI) via photon mapping. We then detail and analyze efficient GPU implementations of four best-of-breed algorithms. All produce reasonable results on NVIDIA GeForce 670 at 1920 × 1080 for complex scenes with multiple-bounce diffuse effects, caustics, and glossy reflection in real-time. Across the designs we conclude that tiled, deferred photon gathering in a compute shader gives the best combination of performance and quality.},
  isbn = {978-1-4503-1956-0},
  file = {/Users/julianstamm/Zotero/storage/SYH49PPN/Mara et al. - 2013 - Toward practical real-time photon mapping efficient GPU density estimation.pdf}
}

@online{mihut,
  type = {Repository},
  title = {{{NRC Integration Guide}}},
  author = {Mihuț, Ana},
  url = {https://github.com/NVIDIA-RTX/RTXGI/blob/main/Docs/NrcGuide.md},
  urldate = {2025-03-22},
  langid = {english},
  organization = {Github},
  file = {/Users/julianstamm/Zotero/storage/74F5A66G/NrcGuide.html}
}

@online{mikkelsena,
  title = {{{MikkTSpace}}.Com},
  author = {Mikkelsen, Morten S.},
  url = {http://www.mikktspace.com/},
  urldate = {2024-08-28},
  file = {/Users/julianstamm/Zotero/storage/M7WN8MUS/www.mikktspace.com.html}
}

@article{muller2017,
  title = {Practical {{Path Guiding}} for {{Efficient Light}}‐{{Transport Simulation}}},
  author = {Müller, Thomas and Gross, Markus and Novák, Jan},
  date = {2017-07},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {36},
  number = {4},
  pages = {91--100},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.13227},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13227},
  urldate = {2025-05-16},
  abstract = {We present a robust, unbiased technique for intelligent light-path construction in path-tracing algorithms. Inspired by existing path-guiding algorithms, our method learns an approximate representation of the scene’s spatio-directional radiance field in an unbiased and iterative manner. To that end, we propose an adaptive spatio-directional hybrid data structure, referred to as SD-tree, for storing and sampling incident radiance. The SD-tree consists of an upper part—a binary tree that partitions the 3D spatial domain of the light field—and a lower part—a quadtree that partitions the 2D directional domain. We further present a principled way to automatically budget training and rendering computations to minimize the variance of the final image. Our method does not require tuning hyperparameters, although we allow limiting the memory footprint of the SD-tree. The aforementioned properties, its ease of implementation, and its stable performance make our method compatible with production environments. We demonstrate the merits of our method on scenes with difficult visibility, detailed geometry, and complex specular-glossy light transport, achieving better performance than previous state-of-the-art algorithms.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/6MUGG4B9/Müller et al. - 2017 - Practical Path Guiding for Efficient Light‐Transport Simulation.pdf}
}

@online{muller2019,
  title = {Neural {{Importance Sampling}}},
  author = {Müller, Thomas and McWilliams, Brian and Rousselle, Fabrice and Gross, Markus and Novák, Jan},
  date = {2019-09-03},
  eprint = {1808.03856},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1808.03856},
  url = {http://arxiv.org/abs/1808.03856},
  urldate = {2025-04-23},
  abstract = {We propose to use deep neural networks for generating samples in Monte Carlo integration. Our work is based on non-linear independent components estimation (NICE), which we extend in numerous ways to improve performance and enable its application to integration problems. First, we introduce piecewise-polynomial coupling transforms that greatly increase the modeling power of individual coupling layers. Second, we propose to preprocess the inputs of neural networks using one-blob encoding, which stimulates localization of computation and improves inference. Third, we derive a gradient-descent-based optimization for the KL and the \$\textbackslash chi\textasciicircum 2\$ divergence for the specific application of Monte Carlo integration with unnormalized stochastic estimates of the target distribution. Our approach enables fast and accurate inference and efficient sample generation independently of the dimensionality of the integration domain. We show its benefits on generating natural images and in two applications to light-transport simulation: first, we demonstrate learning of joint path-sampling densities in the primary sample space and importance sampling of multi-dimensional path prefixes thereof. Second, we use our technique to extract conditional directional densities driven by the product of incident illumination and the BSDF in the rendering equation, and we leverage the densities for path guiding. In all applications, our approach yields on-par or higher performance than competing techniques at equal sample count.},
  pubstate = {prepublished},
  keywords = {Computer Science - Graphics,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/julianstamm/Zotero/storage/E65E8WYE/Müller et al. - 2019 - Neural Importance Sampling.pdf;/Users/julianstamm/Zotero/storage/EPNMQZR3/1808.html}
}

@article{muller2021,
  title = {Real-Time Neural Radiance Caching for Path Tracing},
  author = {Müller, Thomas and Rousselle, Fabrice and Novák, Jan and Keller, Alexander},
  date = {2021-08-31},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {40},
  number = {4},
  pages = {1--16},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3450626.3459812},
  url = {https://dl.acm.org/doi/10.1145/3450626.3459812},
  urldate = {2024-09-24},
  abstract = {We present a real-time neural radiance caching method for path-traced global illumination. Our system is designed to handle fully dynamic scenes, and makes no assumptions about the lighting, geometry, and materials. The data-driven nature of our approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. Since pretraining neural networks to handle novel, dynamic scenes is a formidable generalization challenge, we do away with pretraining and instead achieve               generalization via adaptation               , i.e. we opt for training the radiance cache while rendering. We employ self-training to provide low-noise training targets and simulate infinite-bounce transport by merely iterating few-bounce training updates. The updates and cache queries incur a mild overhead---about 2.6ms on full HD resolution---thanks to a streaming implementation of the neural network that fully exploits modern hardware. We demonstrate significant noise reduction at the cost of little induced bias, and report state-of-the-art, real-time performance on a number of challenging scenarios.},
  langid = {english},
  keywords = {Main},
  file = {/Users/julianstamm/Zotero/storage/RCM58VU2/Müller et al. - 2021 - Real-time neural radiance caching for path tracing.pdf}
}

@article{muller2022,
  title = {Instant Neural Graphics Primitives with a Multiresolution Hash Encoding},
  author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  date = {2022-07},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {41},
  number = {4},
  pages = {1--15},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3528223.3530127},
  url = {https://dl.acm.org/doi/10.1145/3528223.3530127},
  urldate = {2025-04-22},
  abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/G6CDDTGE/Müller et al. - 2022 - Instant neural graphics primitives with a multiresolution hash encoding.pdf}
}

@report{nvidiacorporation2024,
  title = {{{cuRAND Library Programming Guide}}},
  author = {{NVIDIA Corporation}},
  date = {2024-01},
  url = {https://docs.nvidia.com/cuda/pdf/CURAND_Library.pdf},
  file = {/Users/julianstamm/Zotero/storage/5SVTVRWP/CURAND_Library.pdf}
}

@unpublished{oat2005,
  title = {Irradiance {{Volumes For Games}}},
  author = {Oat},
  date = {2005},
  file = {/Users/julianstamm/Zotero/storage/LSMXV8PD/Oat_GDC2005_IrradianceVolumesForGames.pdf}
}

@article{ouyang2021,
  title = {{{ReSTIR GI}}: {{Path Resampling}} for {{Real}}‐{{Time Path Tracing}}},
  shorttitle = {{{ReSTIR GI}}},
  author = {Ouyang, Y. and Liu, S. and Kettunen, M. and Pharr, M. and Pantaleoni, J.},
  date = {2021-12},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {40},
  number = {8},
  pages = {17--29},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.14378},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14378},
  urldate = {2025-04-22},
  abstract = {Even with the advent of hardware-accelerated ray tracing in modern GPUs, only a small number of rays can be traced at each pixel in real-time applications. This presents a significant challenge for path tracing, even when augmented with state-of-the art denoising algorithms. While the recently-developed ReSTIR algorithm [BWP∗20] enables high-quality renderings of scenes with millions of light sources using just a few shadow rays at each pixel, there remains a need for effective algorithms to sample indirect illumination.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/SATQFIQP/Ouyang et al. - 2021 - ReSTIR GI Path Resampling for Real‐Time Path Tracing.pdf}
}

@inproceedings{owen1995,
  title = {Randomly {{Permuted}} (t,m,s)-{{Nets}} and (t, s)-{{Sequences}}},
  booktitle = {Monte {{Carlo}} and {{Quasi-Monte Carlo Methods}} in {{Scientific Computing}}},
  author = {Owen, Art B.},
  editor = {Niederreiter, Harald and Shiue, Peter Jau-Shyong},
  date = {1995},
  pages = {299--317},
  publisher = {Springer},
  location = {New York, NY},
  doi = {10.1007/978-1-4612-2552-2_19},
  abstract = {This article presents a hybrid of Monte Carlo and Quasi-Monte Carlo methods. In this hybrid, certain low discrepancy point sets and sequences due to Faure, Niederreiter and Sobol’ are obtained and their digits are randomly permuted. Since this randomization preserves the equidistribution properties of the points it also preserves the proven bounds on their quadrature errors. The accuracy of an estimated integrand can be assessed by replication, consisting of independent re-randomizations.},
  isbn = {978-1-4612-2552-2},
  langid = {english}
}

@article{owen2008,
  title = {Local Antithetic Sampling with Scrambled Nets},
  author = {Owen, Art B.},
  date = {2008-10-01},
  journaltitle = {The Annals of Statistics},
  shortjournal = {Ann. Statist.},
  volume = {36},
  number = {5},
  eprint = {0811.0528},
  eprinttype = {arXiv},
  eprintclass = {stat},
  issn = {0090-5364},
  doi = {10.1214/07-AOS548},
  url = {http://arxiv.org/abs/0811.0528},
  urldate = {2025-06-15},
  abstract = {We consider the problem of computing an approximation to the integral \$I=\textbackslash int\_\{[0,1]\textasciicircum d\}f(x) dx\$. Monte Carlo (MC) sampling typically attains a root mean squared error (RMSE) of \$O(n\textasciicircum\{-1/2\})\$ from \$n\$ independent random function evaluations. By contrast, quasi-Monte Carlo (QMC) sampling using carefully equispaced evaluation points can attain the rate \$O(n\textasciicircum\{-1+\textbackslash varepsilon\})\$ for any \$\textbackslash varepsilon{$>$}0\$ and randomized QMC (RQMC) can attain the RMSE \$O(n\textasciicircum\{-3/2+\textbackslash varepsilon\})\$, both under mild conditions on \$f\$. Classical variance reduction methods for MC can be adapted to QMC. Published results combining QMC with importance sampling and with control variates have found worthwhile improvements, but no change in the error rate. This paper extends the classical variance reduction method of antithetic sampling and combines it with RQMC. One such method is shown to bring a modest improvement in the RMSE rate, attaining \$O(n\textasciicircum\{-3/2-1/d+\textbackslash varepsilon\})\$ for any \$\textbackslash varepsilon{$>$}0\$, for smooth enough \$f\$.},
  keywords = {Mathematics - Statistics Theory,Statistics - Computation,Statistics - Statistics Theory},
  file = {/Users/julianstamm/Zotero/storage/RKHBFXPF/Owen - 2008 - Local antithetic sampling with scrambled nets.pdf;/Users/julianstamm/Zotero/storage/CQ4H5JJ3/0811.html}
}

@article{qin2015,
  title = {Unbiased Photon Gathering for Light Transport Simulation},
  author = {Qin, Hao and Sun, Xin and Hou, Qiming and Guo, Baining and Zhou, Kun},
  date = {2015-11-04},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {34},
  number = {6},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2816795.2818119},
  url = {https://dl.acm.org/doi/10.1145/2816795.2818119},
  urldate = {2025-05-13},
  abstract = {Photon mapping (PM) has been widely regarded as an efficient solution for light transport simulation, including challenging caustics paths and many-bounce indirect lighting. The efficiency of PM comes from reusing traced photons. However, the handling of photon gathering in existing PM algorithms is universally biased -- the expected value of their results does not necessarily agree with the true solution of the rendering equation. We present a novel photon gathering method to efficiently achieve unbiased rendering with photon mapping. Instead of aggregating the gathered photons into an estimated density as in classical photon mapping, we process each photon individually and connect the corresponding light sub-path with the eye sub-path that generates the gather point, creating an unbiased path sample. The Monte Carlo estimate for such a path sample is calculated by evaluating all relevant terms in a strict and unbiased way, leading to a self-contained unbiased sampling technique. We further develop a set of multiple importance sampling (MIS) weights that allow our method to be optimally combined with bidirectional path tracing (BDPT), resulting in an unbiased rendering algorithm that can efficiently handle a wide variety of light paths and that compares favorably with previous algorithms. Experiments demonstrate the efficacy and robustness of our method.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/K32QSZVB/Qin et al. - 2015 - Unbiased photon gathering for light transport simulation.pdf}
}

@online{reynolds2016,
  title = {Orthonormal Basis from Normal via Quaternion Similarity},
  author = {Reynolds, Marc B.},
  date = {2016-07-06T00:00:00+00:00},
  url = {http://marc-b-reynolds.github.io/quaternions/2016/07/06/Orthonormal.html},
  urldate = {2024-08-28},
  abstract = {two methods of computing an orthonormal basis from a unit (bi)vector.},
  organization = {Marc-B-Reynolds.github.io},
  file = {/Users/julianstamm/Zotero/storage/LJGWWJDN/Orthonormal.html}
}

@article{ritschel2012,
  title = {The {{State}} of the {{Art}} in {{Interactive Global Illumination}}},
  author = {Ritschel, Tobias and Dachsbacher, Carsten and Grosch, Thorsten and Kautz, Jan},
  date = {2012-02},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {31},
  number = {1},
  pages = {160--188},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/j.1467-8659.2012.02093.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2012.02093.x},
  urldate = {2025-05-04},
  abstract = {The interaction of light and matter in the world surrounding us is of striking complexity and beauty. Since the very beginning of computer graphics, adequate modeling of these processes and efficient computation is an intensively studied research topic and still not a solved problem. The inherent complexity stems from the underlying physical processes as well as the global nature of the interactions that let light travel within a scene. This article reviews the state of the art in interactive global illumination computation, that is, methods that generate an image of a virtual scene in less than one second with an as exact as possible, or plausible, solution to the light transport. Additionally, the theoretical background and attempts to classify the broad field of methods are described. The strengths and weaknesses of different approaches, when applied to the different visual phenomena, arising from light interaction are compared and discussed. Finally, the article concludes by highlighting design patterns for interactive global illumination and a list of open problems.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/AB8BRB2D/Ritschel et al. - 2012 - The State of the Art in Interactive Global Illumination.pdf}
}

@online{schutte,
  title = {Rendering the {{Moana Island Scene Part}} 1: {{Implementing}} the {{Disney BSDF}}},
  author = {Schutte, Joe},
  url = {https://schuttejoe.github.io/post/disneybsdf/},
  urldate = {2024-12-21},
  organization = {Importance Sampling techniques for GGX with Smith Masking-Shadowing},
  file = {/Users/julianstamm/Zotero/storage/J4RCFEZ4/disneybsdf.html}
}

@online{schutte2018,
  title = {Importance {{Sampling}} Techniques for {{GGX}} with {{Smith Masking-Shadowing}}: {{Part}} 2},
  author = {Schutte, Joe},
  date = {2018-03-07},
  url = {https://schuttejoe.github.io/post/ggximportancesamplingpart2/},
  urldate = {2024-08-28},
  organization = {Importance Sampling techniques for GGX with Smith Masking-Shadowing},
  file = {/Users/julianstamm/Zotero/storage/XWYF4XPM/ggximportancesamplingpart2.html}
}

@incollection{smal2019,
  title = {Real-{{Time Global Illumination}} with {{Photon Mapping}}},
  booktitle = {Ray {{Tracing Gems}}: {{High-Quality}} and {{Real-Time Rendering}} with {{DXR}} and {{Other APIs}}},
  author = {Smal, Niklas and Aizenshtein, Maksim},
  editor = {Haines, Eric and Akenine-Möller, Tomas},
  date = {2019},
  pages = {409--436},
  publisher = {Apress},
  location = {Berkeley, CA},
  doi = {10.1007/978-1-4842-4427-2_24},
  url = {https://doi.org/10.1007/978-1-4842-4427-2_24},
  urldate = {2025-05-18},
  abstract = {Indirect lighting, also known as global illumination, is a crucial effect in photorealistic images. While there are a number of effective global illumination techniques based on precomputation that work well with static scenes, including global illumination for scenes with dynamic lighting and dynamic geometry remains a challenging problem. In this chapter, we describe a real-time global illumination algorithm based on photon mapping that evaluates several bounces of indirect lighting without any precomputed data in scenes with both dynamic lighting and fully dynamic geometry. We explain both the pre- and post-processing steps required to achieve dynamic high-quality illumination within the limits of a realtime frame budget.},
  isbn = {978-1-4842-4427-2},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/39CXCRPU/Smal and Aizenshtein - 2019 - Real-Time Global Illumination with Photon Mapping.pdf}
}

@inproceedings{takikawa2023,
  title = {Compact {{Neural Graphics Primitives}} with {{Learned Hash Probing}}},
  booktitle = {{{SIGGRAPH Asia}} 2023 {{Conference Papers}}},
  author = {Takikawa, Towaki and Müller, Thomas and Nimier-David, Merlin and Evans, Alex and Fidler, Sanja and Jacobson, Alec and Keller, Alexander},
  date = {2023-12-10},
  pages = {1--10},
  publisher = {ACM},
  location = {Sydney NSW Australia},
  doi = {10.1145/3610548.3618167},
  url = {https://dl.acm.org/doi/10.1145/3610548.3618167},
  urldate = {2025-04-22},
  eventtitle = {{{SA}} '23: {{SIGGRAPH Asia}} 2023},
  isbn = {979-8-4007-0315-7},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/5PV4YKD5/Takikawa et al. - 2023 - Compact Neural Graphics Primitives with Learned Hash Probing.pdf;/Users/julianstamm/Zotero/storage/FQX3VKFC/Takikawa et al. - 2023 - Compact Neural Graphics Primitives with Learned Hash Probing.pdf}
}

@report{thekhronosr3dformatsworkinggroup2021,
  title = {{{glTF}}™  2.0 {{Specification}}},
  author = {{The Khronos® 3D Formats Working Group}},
  date = {2021-10-11}
}

@online{typesraytracing,
  title = {Types of {{Ray Tracing}}},
  url = {https://cs.stanford.edu/people/eroberts/courses/soco/projects/1997-98/ray-tracing/types.html},
  urldate = {2025-04-24},
  file = {/Users/julianstamm/Zotero/storage/LQ5M3P3Z/types.html}
}

@article{veach,
  title = {Metropolis {{Light Transport}}},
  author = {Veach, Eric and Guibas, Leonidas J},
  abstract = {We present a new Monte Carlo method for solving the light transport problem, inspired by the Metropolis sampling method in computational physics. To render an image, we generate a sequence of light transport paths by randomly mutating a single current path (e.g. adding a new vertex to the path). Each mutation is accepted or rejected with a carefully chosen probability, to ensure that paths are sampled according to the contribution they make to the ideal image. We then estimate this image by sampling many paths, and recording their locations on the image plane.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/ZKQBSNMG/Veach and Guibas - Metropolis Light Transport.pdf}
}

@incollection{veach1995,
  title = {Bidirectional {{Estimators}} for {{Light Transport}}},
  booktitle = {Photorealistic {{Rendering Techniques}}},
  author = {Veach, Eric and Guibas, Leonidas},
  editor = {Sakas, Georgios and Müller, Stefan and Shirley, Peter},
  date = {1995},
  pages = {145--167},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-87825-1_11},
  url = {http://link.springer.com/10.1007/978-3-642-87825-1_11},
  urldate = {2025-04-24},
  isbn = {978-3-642-87827-5 978-3-642-87825-1},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/M97AIECC/Veach94.pdf}
}

@thesis{veach1997,
  title = {Robust {{Monte Carlo}} Methods for Light Transport Simulation},
  author = {Veach, Eric},
  date = {1997-12},
  institution = {Stanford University},
  url = {https://graphics.stanford.edu/papers/veach_thesis/thesis.pdf},
  urldate = {2024-12-21},
  file = {/Users/julianstamm/Zotero/storage/5PLIJRDX/veach1997.pdf;/Users/julianstamm/Zotero/storage/FHZR7F3K/veach-chapter9.pdf}
}

@article{vorba,
  title = {Bidirectional {{Photon Mapping}}},
  author = {Vorba, Jiˇrı},
  abstract = {This paper introduces a method for optimal combination of light paths generated from the camera and from the light sources in the photon mapping algorithm used for computing global illumination. Our method is based on Multiple Importance Sampling, a general approach, introduced by Veach, for adaptive path connection in bi-directional pathtracing. Our goal is to examine this method in connection with the biased algorithm of photon mapping and to improve the ineffective final gather heuristic used in the original version of this algorithm. This heuristic is usually problematic when applied to the scenes where highly glossy materials prevail.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/T4U58Q9V/Vorba - Bidirectional Photon Mapping.pdf}
}

@book{walter2007a,
  title = {Microfacet {{Models}} for {{Refraction}} through {{Rough Surfaces}}},
  author = {Walter, Bruce and Marschner, Stephen R. and Li, Hongsong and Torrance, Kenneth E.},
  date = {2007},
  publisher = {The Eurographics Association},
  issn = {1727-3463},
  url = {https://doi.org/10.2312/EGWR/EGSR07/195-206},
  urldate = {2025-05-18},
  abstract = {Microfacet models have proven very successful for modeling light reflection from rough surfaces. In this paper we review microfacet theory and demonstrate how it can be extended to simulate transmission through rough surfaces such as etched glass. We compare the resulting transmission model to measured data from several real surfaces and discuss appropriate choices for the microfacet distribution and shadowing-masking functions. Since rendering transmission through media requires tracking light that crosses at least two interfaces, good importance sampling is a practical necessity. Therefore, we also describe efficient schemes for sampling the microfacet models and the corresponding probability density functions.},
  isbn = {978-3-905673-52-4},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/76DZLBXJ/Walter et al. - 2007 - Microfacet Models for Refraction through Rough Surfaces.pdf}
}

@article{ward1988,
  title = {A Ray Tracing Solution for Diffuse Interreflection},
  author = {Ward, Gregory J. and Rubinstein, Francis M. and Clear, Robert D.},
  date = {1988-08},
  journaltitle = {ACM SIGGRAPH Computer Graphics},
  shortjournal = {SIGGRAPH Comput. Graph.},
  volume = {22},
  number = {4},
  pages = {85--92},
  issn = {0097-8930},
  doi = {10.1145/378456.378490},
  url = {https://dl.acm.org/doi/10.1145/378456.378490},
  urldate = {2025-04-22},
  abstract = {An efficient ray tracing method is presented for calculating interreflections between surfaces with both diffuse and specular components. A Monte Carlo technique computes the indirect contributions to illuminance at locations chosen by the rendering process. The indirect illuminance values are averaged over surfaces and used in place of a constant "ambient" term. Illuminance calculations are made only for those areas participating in the selected view, and the results are stored so that subsequent views can reuse common values. The density of the calculation is adjusted to maintain a constant accuracy, permitting less populated portions of the scene to be computed quickly. Successive reflections use proportionally fewer samples, which speeds the process and provides a natural limit to recursion. The technique can also model diffuse transmission and illumination from large area sources, such as the sky.},
  langid = {english},
  file = {/Users/julianstamm/Zotero/storage/X22JZBZ4/Ward et al. - 1988 - A ray tracing solution for diffuse interreflection.pdf}
}

@inproceedings{zheng2024,
  title = {Neural {{Global Illumination}} via {{Superposed Deformable Feature Fields}}},
  booktitle = {{{SIGGRAPH Asia}} 2024 {{Conference Papers}}},
  author = {Zheng, Chuankun and Huo, Yuchi and Huang, Hongxiang and Sheng, Hongtao and Huang, Junrong and Tang, Rui and Zhu, Hao and Wang, Rui and Bao, Hujun},
  date = {2024-12-03},
  series = {{{SA}} '24},
  pages = {1--11},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3680528.3687680},
  url = {https://doi.org/10.1145/3680528.3687680},
  urldate = {2025-05-04},
  abstract = {Interactive rendering of dynamic scenes with complex global illumination has been a long-standing problem in computer graphics. Recent advances in neural rendering demonstrate new promising possibilities. However, while existing methods have achieved impressive results, complex rendering effects (e.g., caustics) remain challenging. This paper presents a novel neural rendering method that is able to generate high-quality global illumination effects, including but not limited to caustics, soft shadows, and indirect highlights, for dynamic scenes with varying camera, lighting conditions, materials, and object transformations. Inspired by object-oriented transfer field representations, we employ deformable neural feature fields to implicitly model the impacts of individual objects or light sources on global illumination. By employing neural feature fields, our method gains the ability to represent high-frequency details, thus supporting complex rendering effects. We superpose these feature fields in latent space and utilize a lightweight decoder to obtain global illumination estimates, which allows our neural representations to spontaneously adapt to the contribution of individual objects or light sources to global illumination in a data-driven manner, thus further improving the quality. Our experiments demonstrate the effectiveness of our method on a wide range of scenes with complex light paths, materials, and geometries.},
  isbn = {979-8-4007-1131-2}
}

@article{zhou2008,
  title = {Real-Time {{KD-tree}} Construction on Graphics Hardware},
  author = {Zhou, Kun and Hou, Qiming and Wang, Rui and Guo, Baining},
  date = {2008-12-01},
  journaltitle = {ACM Trans. Graph.},
  volume = {27},
  number = {5},
  pages = {126:1--126:11},
  issn = {0730-0301},
  doi = {10.1145/1409060.1409079},
  url = {https://doi.org/10.1145/1409060.1409079},
  urldate = {2025-05-13},
  abstract = {We present an algorithm for constructing kd-trees on GPUs. This algorithm achieves real-time performance by exploiting the GPU's streaming architecture at all stages of kd-tree construction. Unlike previous parallel kd-tree algorithms, our method builds tree nodes completely in BFS (breadth-first search) order. We also develop a special strategy for large nodes at upper tree levels so as to further exploit the fine-grained parallelism of GPUs. For these nodes, we parallelize the computation over all geometric primitives instead of nodes at each level. Finally, in order to maintain kd-tree quality, we introduce novel schemes for fast evaluation of node split costs.As far as we know, ours is the first real-time kd-tree algorithm on the GPU. The kd-trees built by our algorithm are of comparable quality as those constructed by off-line CPU algorithms. In terms of speed, our algorithm is significantly faster than well-optimized single-core CPU algorithms and competitive with multi-core CPU algorithms. Our algorithm provides a general way for handling dynamic scenes on the GPU. We demonstrate the potential of our algorithm in applications involving dynamic scenes, including GPU ray tracing, interactive photon mapping, and point cloud modeling.}
}

@online{zhu2020,
  title = {Deep {{Photon Mapping}}},
  author = {Zhu, Shilin and Xu, Zexiang and Jensen, Henrik Wann and Su, Hao and Ramamoorthi, Ravi},
  date = {2020-04-25},
  eprint = {2004.12069},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2004.12069},
  url = {http://arxiv.org/abs/2004.12069},
  urldate = {2025-04-30},
  abstract = {Recently, deep learning-based denoising approaches have led to dramatic improvements in low sample-count Monte Carlo rendering. These approaches are aimed at path tracing, which is not ideal for simulating challenging light transport effects like caustics, where photon mapping is the method of choice. However, photon mapping requires very large numbers of traced photons to achieve high-quality reconstructions. In this paper, we develop the first deep learning-based method for particle-based rendering, and specifically focus on photon density estimation, the core of all particle-based methods. We train a novel deep neural network to predict a kernel function to aggregate photon contributions at shading points. Our network encodes individual photons into per-photon features, aggregates them in the neighborhood of a shading point to construct a photon local context vector, and infers a kernel function from the per-photon and photon local context features. This network is easy to incorporate in many previous photon mapping methods (by simply swapping the kernel density estimator) and can produce high-quality reconstructions of complex global illumination effects like caustics with an order of magnitude fewer photons compared to previous photon mapping methods.},
  pubstate = {prepublished},
  keywords = {Computer Science - Graphics,Computer Science - Machine Learning},
  file = {/Users/julianstamm/Zotero/storage/7L3ATJ4C/Zhu et al. - 2020 - Deep Photon Mapping.pdf;/Users/julianstamm/Zotero/storage/YER4TY8K/2004.html}
}

@online{zhu2022a,
  title = {{{RTNN}}: {{Accelerating Neighbor Search Using Hardware Ray Tracing}}},
  shorttitle = {{{RTNN}}},
  author = {Zhu, Yuhao},
  date = {2022-03-09},
  eprint = {2201.01366},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.01366},
  url = {http://arxiv.org/abs/2201.01366},
  urldate = {2025-05-30},
  abstract = {Neighbor search is of fundamental important to many engineering and science fields such as physics simulation and computer graphics. This paper proposes to formulate neighbor search as a ray tracing problem and leverage the dedicated ray tracing hardware in recent GPUs for acceleration. We show that a naive mapping under-exploits the ray tracing hardware. We propose two performance optimizations, query scheduling and query partitioning, to tame the inefficiencies. Experimental results show 2.2X -- 65.0X speedups over existing neighbor search libraries on GPUs. The code is available at https://github.com/horizon-research/rtnn.},
  pubstate = {prepublished},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Graphics},
  file = {/Users/julianstamm/Zotero/storage/8ZNSAYGQ/Zhu - 2022 - RTNN Accelerating Neighbor Search Using Hardware Ray Tracing.pdf;/Users/julianstamm/Zotero/storage/LI67UZPS/2201.html}
}

@inreference{zordercurve2025,
  title = {Z-Order Curve},
  booktitle = {Wikipedia},
  date = {2025-02-08T19:21:58Z},
  url = {https://en.wikipedia.org/w/index.php?title=Z-order_curve&oldid=1274694704},
  urldate = {2025-05-30},
  abstract = {In mathematical analysis and computer science, functions which are Z-order, Lebesgue curve, Morton space-filling curve, Morton order or Morton code map multidimensional data to one dimension while preserving locality of the data points (two points close together in multidimensions with high probability lie also close together in Morton order). It is named in France after Henri Lebesgue, who studied it in 1904, and named in the United States after Guy Macdonald Morton, who first applied the order to file sequencing in 1966. The z-value of a point in multidimensions is simply calculated by bit interleaving the binary representations of its coordinate values. However, when querying a multidimensional search range in these data, using binary search is not really efficient: It is necessary for calculating, from a point encountered in the data structure, the next possible Z-value which is in the multidimensional search range, called BIGMIN. The BIGMIN problem has first been stated and its solution shown by Tropf and Herzog in 1981. Once the data are sorted by bit interleaving, any one-dimensional data structure can be used, such as simple one dimensional arrays, binary search trees, B-trees, skip lists or (with low significant bits truncated) hash tables. The resulting ordering can equivalently be described as the order one would get from a depth-first traversal of a quadtree or octree.},
  langid = {english},
  annotation = {Page Version ID: 1274694704},
  file = {/Users/julianstamm/Zotero/storage/3BWLCJ5L/index.html}
}
